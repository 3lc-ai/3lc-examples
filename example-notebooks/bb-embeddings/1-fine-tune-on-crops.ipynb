{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning a Classifier Using Bounding Box Data from a 3LC Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD LINKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"Bounding Box Classifier\"\n",
    "EPOCHS = 10\n",
    "TEST_DATA_PATH = \"../../data\"\n",
    "TRANSIENT_DATA_PATH = \"../../transient_data\"\n",
    "BATCH_SIZE = 32\n",
    "DATASET_NAME = \"Bounding Box Classification Dataset\"\n",
    "DEVICE = None\n",
    "TLC_PUBLIC_EXAMPLES_DEVELOPER_MODE = True\n",
    "INSTALL_DEPENDENCIES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if INSTALL_DEPENDENCIES:\n",
    "    %pip --quiet install torch --index-url https://download.pytorch.org/whl/cu118\n",
    "    %pip --quiet install torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "    %pip --quiet install timm\n",
    "    %pip --quiet install 3lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from io import BytesIO\n",
    "\n",
    "import timm\n",
    "import tlc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import tqdm.notebook as tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEVICE is None:\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "else:\n",
    "    device = DEVICE\n",
    "\n",
    "device = torch.device(device)\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Input Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_url = tlc.Url.create_table_url(project_name=PROJECT_NAME, dataset_name=DATASET_NAME, table_name=\"table_from_coco\")\n",
    "\n",
    "annotations_file = tlc.Url(TEST_DATA_PATH + \"/balloons/train/train-annotations.json\").to_absolute()\n",
    "images_dir = tlc.Url(TEST_DATA_PATH + \"/balloons/train\").to_absolute()\n",
    "\n",
    "input_table = tlc.Table.from_coco(\n",
    "    table_url=table_url,\n",
    "    annotations_file=annotations_file,\n",
    "    image_folder=images_dir,\n",
    "    description=\"Balloons training dataset from COCO annotations\",\n",
    "    if_exists=\"overwrite\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the schema of the bounding box column of the input table\n",
    "bb_schema = input_table.schema.values[\"rows\"].values[\"bbs\"].values[\"bb_list\"]\n",
    "label_map = input_table.get_value_map(\"bbs.bb_list.label\")\n",
    "print(f\"Input table uses {len(label_map)} unique labels: {json.dumps(label_map, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the number of bounding boxes per image to control sampling\n",
    "num_bbs_per_image = [len(row[\"bbs\"][\"bb_list\"]) for row in input_table.table_rows]\n",
    "sampler = WeightedRandomSampler(num_bbs_per_image, num_samples=len(input_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of custom dataset class\n",
    "class BBCropDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        table: tlc.Table,\n",
    "        transform=None,\n",
    "        save_images_dir: str = \"\",\n",
    "        random_seed: int = 42,\n",
    "        is_train: bool = True,\n",
    "        background_freq: float = 0.5,\n",
    "    ):\n",
    "        self.table = table\n",
    "        self.bb_schema = table.schema.values[\"rows\"].values[\"bbs\"].values[\"bb_list\"]\n",
    "        self.transform = transform\n",
    "        self.save_images_dir = save_images_dir\n",
    "        self.used_bbs = defaultdict(set)\n",
    "        self.is_train = is_train\n",
    "        self.background_freq = background_freq\n",
    "        self.random_gen = random.Random(random_seed)\n",
    "\n",
    "        self.label_map = table.get_value_map(\"bbs.bb_list.label\")\n",
    "        self.background_label = len(self.label_map)\n",
    "\n",
    "        # Create mappings for contiguous IDs (in case label map is not contiguous)\n",
    "        self.id_to_contiguous = {\n",
    "            original_id: contiguous_id for contiguous_id, original_id in enumerate(self.label_map.keys())\n",
    "        }\n",
    "        self.contiguous_to_id = {\n",
    "            contiguous_id: original_id for original_id, contiguous_id in self.id_to_contiguous.items()\n",
    "        }\n",
    "        self.num_classes = len(self.label_map)\n",
    "\n",
    "        if background_freq > 0:\n",
    "            self.num_classes += 1  # Adding 1 for background class\n",
    "\n",
    "        if self.save_images_dir:\n",
    "            os.makedirs(self.save_images_dir, exist_ok=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.table.table_rows[idx]\n",
    "\n",
    "        image_filename = row[\"image\"]\n",
    "        image_bbs = row[\"bbs\"][\"bb_list\"]\n",
    "\n",
    "        if len(image_bbs) == 0:\n",
    "            raise ValueError(f\"Image {image_filename} has no bounding boxes. Use a sampler that excludes these images.\")\n",
    "\n",
    "        image_bytes = tlc.Url(image_filename).read()\n",
    "        image = Image.open(BytesIO(image_bytes))\n",
    "        w, h = image.size\n",
    "\n",
    "        available_bbs_idxs = list(set(range(len(image_bbs))) - self.used_bbs[idx])\n",
    "\n",
    "        if not available_bbs_idxs:\n",
    "            # print(f\"Re-using bbs from sample {idx}\")\n",
    "            self.used_bbs[idx] = set()\n",
    "            available_bbs_idxs = list(range(len(image_bbs)))\n",
    "\n",
    "        random_bb_idx = random.choice(available_bbs_idxs)\n",
    "\n",
    "        is_background = False\n",
    "        if self.random_gen.random() < self.background_freq and self.is_train:\n",
    "            is_background = True\n",
    "            gt_boxes = row[\"bbs\"][\"bb_list\"]\n",
    "            background_patch = self._generate_background(image, gt_boxes, w, h)\n",
    "            crop = background_patch\n",
    "            label = torch.tensor(self.background_label, dtype=torch.int64)\n",
    "        else:\n",
    "            random_bb = image_bbs[random_bb_idx]\n",
    "            self.used_bbs[idx].add(random_bb_idx)\n",
    "            crop = tlc.BBCropInterface.crop(image, random_bb, self.bb_schema, image_height=h, image_width=w)\n",
    "            label = torch.tensor(self.id_to_contiguous[random_bb[\"label\"]], dtype=torch.int64)\n",
    "\n",
    "        if self.save_images_dir:\n",
    "            crop.save(\n",
    "                os.path.join(self.save_images_dir, f\"{idx}_{random_bb_idx}{'_background' if is_background else ''}.jpg\")\n",
    "            )\n",
    "\n",
    "        if self.transform:\n",
    "            crop = self.transform(crop)\n",
    "\n",
    "        return crop, label\n",
    "\n",
    "    @staticmethod\n",
    "    def _intersects(box1: list[int], box2: list[int]) -> bool:\n",
    "        x1, y1, w1, h1 = box1\n",
    "        x2, y2, w2, h2 = box2\n",
    "\n",
    "        # Check for non-overlapping conditions\n",
    "        if x1 + w1 < x2 or x2 + w2 < x1 or y1 + h1 < y2 or y2 + h2 < y1:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def _generate_background(\n",
    "        self, image: Image.Image, gt_boxes: list, image_width: int, image_height: int\n",
    "    ) -> Image.Image:\n",
    "        \"\"\"Generate a background patch.\"\"\"\n",
    "        image_width, image_height = image.size\n",
    "        bb_factory = tlc.BoundingBox.from_schema(self.bb_schema)\n",
    "        gt_boxes_xywh = [\n",
    "            bb_factory([bb[\"x0\"], bb[\"y0\"], bb[\"x1\"], bb[\"y1\"]])\n",
    "            .to_top_left_xywh()\n",
    "            .denormalize(image_width, image_height)\n",
    "            for bb in gt_boxes\n",
    "        ]\n",
    "\n",
    "        # Loop until a valid background bounding box is generated\n",
    "        while True:\n",
    "            # Generate proposal box using normal distribution for x, h, w, y\n",
    "            x = max(\n",
    "                min(int(self.random_gen.normalvariate(mu=image_width // 2, sigma=image_width // 6)), image_width - 1), 0\n",
    "            )\n",
    "            y = max(\n",
    "                min(\n",
    "                    int(self.random_gen.normalvariate(mu=image_height // 2, sigma=image_height // 6)), image_height - 1\n",
    "                ),\n",
    "                0,\n",
    "            )\n",
    "            w = max(\n",
    "                min(int(self.random_gen.normalvariate(mu=image_width // 8, sigma=image_width // 16)), image_width - x),\n",
    "                1,\n",
    "            )\n",
    "            h = max(\n",
    "                min(\n",
    "                    int(self.random_gen.normalvariate(mu=image_height // 8, sigma=image_height // 16)), image_height - y\n",
    "                ),\n",
    "                1,\n",
    "            )\n",
    "\n",
    "            proposal_box = [x, y, w, h]\n",
    "\n",
    "            if not any(self._intersects(proposal_box, gt_box) for gt_box in gt_boxes_xywh):\n",
    "                break\n",
    "\n",
    "        # Crop the background patch from the image using the proposal_box\n",
    "        background_patch = image.crop((x, y, x + w, y + h))\n",
    "        return background_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.3),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = BBCropDataset(input_table, transform=train_transforms, is_train=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\"efficientnet_b0\", pretrained=True, num_classes=train_dataset.num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9516)\n",
    "\n",
    "best_accuracy = 0\n",
    "n_iter = 0\n",
    "iteration = []\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(tqdm.tqdm(train_dataloader)):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch >= 5:\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a pth file:\n",
    "torch.save(model.state_dict(), TRANSIENT_DATA_PATH + \"/bb_classifier.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
