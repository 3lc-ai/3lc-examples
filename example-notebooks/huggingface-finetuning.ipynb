{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed546a60",
   "metadata": {},
   "source": [
    "# Fine-tuning a model with the ðŸ¤— TLC Trainer API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c761342",
   "metadata": {},
   "source": [
    "<div style=\"display: inline-flex; align-items: center; gap: 10px;\">\n",
    "        <a href=\"https://colab.research.google.com/github/3lc-ai/3lc-examples/blob/main/example-notebooks/huggingface-finetuning.ipynb\"\n",
    "        target=\"_blank\"\n",
    "            style=\"background-color: transparent; text-decoration: none; display: inline-flex; align-items: center;\n",
    "            padding: 5px 10px; font-family: Arial, sans-serif;\"> <img\n",
    "            src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" style=\"height: 30px;\n",
    "            vertical-align: middle;box-shadow: none;\"/>\n",
    "        </a> <a href=\"https://github.com/3lc-ai/3lc-examples/blob/main/example-notebooks/huggingface-finetuning.ipynb\"\n",
    "            style=\"text-decoration: none; display: inline-flex; align-items: center; background-color: #ffffff; border:\n",
    "            1px solid #d1d5da; border-radius: 8px; padding: 2px 10px; color: #333; font-family: Arial, sans-serif;\">\n",
    "            <svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-mark-github\" viewBox=\"0 0 16 16\"\n",
    "            width=\"20\" height=\"20\" fill=\"#333\"\n",
    "            style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible; margin-right:\n",
    "            8px;\">\n",
    "                <path d=\"M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2\n",
    "                0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0\n",
    "                0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16\n",
    "                1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51\n",
    "                1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68\n",
    "                1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z\"></path>\n",
    "            </svg> <span style=\"vertical-align: middle; color: #333;\">Open in GitHub</span>\n",
    "        </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e70a5a",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use our hugging face TLC Trainer API and finetuning a model called bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22d206",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"bert-base-uncased\"\n",
    "RUN_NAME = \"finetuning-run\"\n",
    "DESCRIPTION = \"Fine-tuning BERT on MRPC\"\n",
    "TRAIN_DATASET_NAME = \"hugging-face-train\"\n",
    "VAL_DATASET_NAME = \"hugging-face-val\"\n",
    "CHECKPOINT = \"bert-base-uncased\"\n",
    "DEVICE = None\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "EVAL_BATCH_SIZE = 256\n",
    "EPOCHS = 4\n",
    "OPTIMIZER = \"adamw_torch\"\n",
    "TRANSIENT_DATA_PATH = \"../transient_data\"\n",
    "TLC_PUBLIC_EXAMPLES_DEVELOPER_MODE = True\n",
    "INSTALL_DEPENDENCIES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06222232",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if INSTALL_DEPENDENCIES:\n",
    "    %pip --quiet install torch --index-url https://download.pytorch.org/whl/cu118\n",
    "    %pip --quiet install torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "    %pip --quiet install accelerate\n",
    "    %pip --quiet install scikit-learn\n",
    "    %pip --quiet install 3lc[huggingface]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484a8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, TrainingArguments\n",
    "\n",
    "import tlc\n",
    "\n",
    "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"true\"  # Removing BertTokenizerFast tokenizer warning\n",
    "\n",
    "datasets.utils.logging.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0a05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEVICE is None:\n",
    "    if torch.cuda.is_available():\n",
    "        DEVICE = \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        DEVICE = \"mps\"\n",
    "    else:\n",
    "        DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2190cc",
   "metadata": {},
   "source": [
    "## Initialize a 3LC Run\n",
    "\n",
    "We initialize a Run with a call to `tlc.init`, and add the configuration to the Run object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bcab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = tlc.init(\n",
    "    project_name=PROJECT_NAME,\n",
    "    run_name=RUN_NAME,\n",
    "    description=DESCRIPTION,\n",
    "    if_exists=\"overwrite\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf42109",
   "metadata": {},
   "source": [
    "With the 3LC integration, you can use `tlc.Table.from_hugging_face()` as a drop-in replacement for\n",
    "`datasets.load_dataset()` to create a `tlc.Table`. Notice `.latest()`, which gets the latest version of the 3LC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f92706",
   "metadata": {},
   "outputs": [],
   "source": [
    "tlc_train_dataset = tlc.Table.from_hugging_face(\n",
    "    \"glue\",\n",
    "    \"mrpc\",\n",
    "    split=\"train\",\n",
    "    project_name=PROJECT_NAME,\n",
    "    dataset_name=TRAIN_DATASET_NAME,\n",
    "    if_exists=\"overwrite\",\n",
    ").latest()\n",
    "\n",
    "tlc_val_dataset = tlc.Table.from_hugging_face(\n",
    "    \"glue\",\n",
    "    \"mrpc\",\n",
    "    split=\"validation\",\n",
    "    project_name=PROJECT_NAME,\n",
    "    dataset_name=VAL_DATASET_NAME,\n",
    "    if_exists=\"overwrite\",\n",
    ").latest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab94d523",
   "metadata": {},
   "source": [
    "`Table` provides a method `map` to apply both preprocessing and on-the-fly transforms to your data before it is sent to the model.\n",
    "\n",
    "It is different from huggingface where it generates a new reference of the data directly including the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7260bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
    "\n",
    "\n",
    "def tokenize_function_tlc(example):\n",
    "    return {**example, **tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)}\n",
    "\n",
    "\n",
    "tlc_tokenized_dataset_train = tlc_train_dataset.map(tokenize_function_tlc)\n",
    "tlc_tokenized_dataset_val = tlc_val_dataset.map(tokenize_function_tlc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3973c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae902e0",
   "metadata": {},
   "source": [
    "Here we define our model with two labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd74761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration purposes, we use the bert-base-uncased model with a different set of labels than\n",
    "# it was trained on. As a result, there will be a warning about the inconsistency of the classifier and\n",
    "# pre_classifier weights. This is expected and can be ignored.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(CHECKPOINT, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675ee45f",
   "metadata": {},
   "source": [
    "## Setup Metrics Collection\n",
    "Computing metrics is done by implementing a function which returns per-sample metrics you would like to see in the 3LC Dashboard. \n",
    "\n",
    "This is different from the original compute_metrics of Huggingface which compute per batch the metrics. Here we want to find results with a granularity of per sample basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a25b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tlc_metrics(logits, labels):\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "    predictions = logits.argmax(dim=-1)\n",
    "    loss = torch.nn.functional.cross_entropy(logits, labels, reduction=\"none\")\n",
    "    confidence = probabilities.gather(dim=-1, index=predictions.unsqueeze(-1)).squeeze()\n",
    "\n",
    "    return {\n",
    "        \"predicted\": predictions,\n",
    "        \"loss\": loss,\n",
    "        \"confidence\": confidence,\n",
    "    }\n",
    "\n",
    "\n",
    "id2label = {0: \"not_equivalent\", 1: \"equivalent\"}\n",
    "schemas = {\n",
    "    \"predicted\": tlc.CategoricalLabelSchema(\n",
    "        display_name=\"Predicted Label\", class_names=id2label.values(), display_importance=4005\n",
    "    ),\n",
    "    \"loss\": tlc.Schema(display_name=\"Loss\", writable=False, value=tlc.Float32Value()),\n",
    "    \"confidence\": tlc.Schema(display_name=\"Confidence\", writable=False, value=tlc.Float32Value()),\n",
    "}\n",
    "compute_tlc_metrics.column_schemas = schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e969557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add references to the input datasets used by the Run.\n",
    "run.add_input_table(tlc_train_dataset)\n",
    "run.add_input_table(tlc_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58830600",
   "metadata": {},
   "source": [
    "## Train the model with TLCTrainer\n",
    "\n",
    "To perform model training, we replace the usual `Trainer` with `TLCTrainer` and provide the per-sample metrics collection function. \n",
    "\n",
    "In this example, we still compute the glue MRPC per batch thanks to the *compute_hf_metrics* method (*compute_metrics* is changed to *compute_hf_metric*s to avoid confusion).\n",
    "\n",
    "We also compute our special per sample tlc metrics thanks to the *compute_tlc_metrics* method.\n",
    "\n",
    "With this latter, we can choose when to start to collect the metrics, here at epoch 2 (indexed from 0 with *tlc_metrics_collection_start*) with a frequency of 1 epoch (with *tlc_metrics_collection_epoch_frequency*).\n",
    "\n",
    "You also can switch the strategy to compute the metrics to \"steps\" in the evaluation_strategy and specify the frequency with *eval_steps*. At this stage, if you use *tlc_metrics_collection_start*, it should be a multiple of *eval_steps*. Note that *tlc_metrics_collection_epoch_frequency* is disable in this case because we use the original *eval_steps* variable.\n",
    "\n",
    "We also specify that we would like to collect metrics prior to training with *compute_tlc_metrics_on_train_begin*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df05d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tlc.integration.hugging_face import TLCTrainer\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=TRANSIENT_DATA_PATH,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
    "    optim=OPTIMIZER,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    report_to=\"none\",  # Disable wandb logging\n",
    "    use_cpu=DEVICE == \"cpu\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    disable_tqdm=True,\n",
    "    # evaluation_strategy=\"steps\",  # For running metrics on steps\n",
    "    # eval_steps=20,  # For running metrics on steps\n",
    ")\n",
    "\n",
    "trainer = TLCTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tlc_tokenized_dataset_train,\n",
    "    eval_dataset=tlc_tokenized_dataset_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_hf_metrics=compute_metrics,\n",
    "    compute_tlc_metrics=compute_tlc_metrics,\n",
    "    compute_tlc_metrics_on_train_begin=True,\n",
    "    compute_tlc_metrics_on_train_end=False,\n",
    "    tlc_metrics_collection_start=2,\n",
    "    tlc_metrics_collection_epoch_frequency=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0df0f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
