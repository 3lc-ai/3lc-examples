{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Step 1: Manually externalize bulk data using a BulkDataProcessor\n",
    "\n",
    "In this first step, we simply externalize manually using a BulkDataProcessor.\n",
    "This is exactly what happens inside a TableWriter by default: bulk-data paths\n",
    "are identified and sibling paths with the \"_binary_property_url\" suffix are\n",
    "added, with contents of the form `<base>/<key><chunk-num>.raw:<start-offset>-<length>`\n",
    "\n",
    "The original key is set to None once the data has been written to disk.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "input_row = {\n",
    "    \"vertices_2d\": np.array([0, 0, 1, 1, 2, 2, 3, 3]) # 4 2d points\n",
    "}\n",
    "\n",
    "BulkDataProcessor(bulk_data_url=\"C:/Temp\").process_row(input_row)\n",
    "\n",
    "{\n",
    "    \"vertices_2d\": None,\n",
    "    \"vertices_2d_binary_property_url\": \"C:/temp/chunk-0.raw:0-32\"\n",
    "}\n",
    "```\n",
    "\n",
    "> Note:\n",
    "> This will only work in practice for columns with schemas deriving from Geometry2DSchema or Geometry3DSchema (so the example above is for reference only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tlc\n",
    "from data_sources import random_array_generator\n",
    "from tlc.core.helpers.bulk_data_helper import BulkDataRowProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Setup a schema for a column containing 2d-points and intensity per point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = tlc.Geometry2DSchema(\n",
    "    include_2d_vertices=True,\n",
    "    per_vertex_schemas={\"intensity\": tlc.Float32ListSchema()},\n",
    "    is_bulk_data=True,  # This is what sets up the \"sibling\" paths with the \"_binary_property_url\" suffix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_data_paths = tlc.SchemaHelper.get_bulk_data_values(schema)\n",
    "bulk_data_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Define a BulkDataRowProcessor configured for writing bulk data to a local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_bulk_data_folder = Path(\"bulk_data/1\").absolute()\n",
    "local_bulk_data_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bulk_data_processor = BulkDataRowProcessor(\n",
    "    table_url=None, paths=bulk_data_paths, bulk_data_url=tlc.Url(local_bulk_data_folder.as_posix())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Helpers for generating random arrays of given shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_2d_generator = random_array_generator((4, 2))  # generates 4 2d points at a time\n",
    "intensity_generator = random_array_generator((4,), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(points_2d_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(intensity_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Create a single row value using the Geometry2DInstances helper-dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = tlc.Geometry2DInstances.create_empty(0, 0, 1, 1, per_vertex_extras_keys=[\"intensity\"])\n",
    "geo.add_instance(vertices=next(points_2d_generator), per_vertex_extras={\"intensity\": next(intensity_generator)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo.to_row()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "This is where the magic happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_row = bulk_data_processor.process_row(geo.to_row())\n",
    "processed_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_data_processor.close_all()  # Ensure files are closed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The input row has been recursively visited, any bulk data paths\n",
    "(\"instances.vertices_2d\", \"instances.vertices_2d_additional_data.intensity\")\n",
    "have been written to disk and nulled, sibling binary property urls pointing to\n",
    "written files/offsets have been added to the row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Now write the pre-externalized data to a Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_writer = tlc.TableWriter(\n",
    "    table_name=\"pre-externalized-table\",\n",
    "    dataset_name=\"pre-externalized-dataset\",\n",
    "    project_name=\"External Bulk Data\",\n",
    "    description=\"Pre-externalized table\",\n",
    "    column_schemas={\"vertices\": schema},  # We use the same schema as before\n",
    "    if_exists=\"rename\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we add_row with a row that has already been processed, nothing will\n",
    "# happen (BulkDataRowProcessor.process_row is idempotent)\n",
    "table_writer.add_row({\"vertices\": processed_row})\n",
    "table = table_writer.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "access the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "table[0][\"vertices\"]  # Table data just contains None / empties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Use a BulkDataAccessor if access to the underlying arrays is required in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tlc.core.helpers.bulk_data_helper import BulkDataAccessor\n",
    "\n",
    "accessor = BulkDataAccessor(table)\n",
    "row = accessor[0]\n",
    "row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
