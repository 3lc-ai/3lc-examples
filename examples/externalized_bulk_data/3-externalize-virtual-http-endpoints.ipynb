{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "261bd611",
   "metadata": {},
   "source": [
    "# Step 3: Virtualize bulk data through an external service\n",
    "\n",
    "In this final version of our story, we will again be writing a Table with manually created bulk data Urls.\n",
    "But instead of writing the bulk data to files, we will only write a lookup table, which will then be used by an\n",
    "external HTTP server for serving chunks dynamically.\n",
    "\n",
    "The trick: we need to know how a 3LC bulk data url resolves to a slice of our source data.\n",
    "\n",
    "E.g. when receiving a request at \"http://localhost:2233/chunk-0:100-200\", we must check a lookup table\n",
    "\n",
    "```\n",
    "{\n",
    "    \"chunk-0\": {\n",
    "        \"0-100\": {\"sample\": 0, \"attribute\": \"vertices_2d\"},\n",
    "        \"100-50\": {\"sample\": 0, \"attribute\": \"intensities\"},\n",
    "        \"150-100\": {\"sample\": 1, \"attribute\": \"vertices_2d\"}\n",
    "        \"250-50\": {\"sample\": 1, attribute\": \"intensities\"}\n",
    "    },\n",
    "    \"chunk-1\": ...\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "to find something we can resolve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726dc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tlc\n",
    "from pathlib import Path\n",
    "from data_sources import Deterministic3DPointCloudDataset\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8bb5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_data_path = Path(\"bulk_data/3\").absolute()\n",
    "lookup_table_path = bulk_data_path / \"lookup_table.json\"\n",
    "\n",
    "server_root = \"http://localhost:2233\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Deterministic3DPointCloudDataset(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941e6ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "rows = []\n",
    "chunk_offsets = defaultdict(int)\n",
    "lookup_table = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    chunk = i // 3\n",
    "    data = dataset[i]\n",
    "    intensities: np.ndarray = data[\"intensities\"]\n",
    "    vertices_3d: np.ndarray = data[\"vertices_3d\"]\n",
    "    vertices_3d_length = np.prod(vertices_3d.shape) * vertices_3d.dtype.itemsize\n",
    "    intensities_length = np.prod(intensities.shape) * intensities.dtype.itemsize\n",
    "\n",
    "    vertices_range = f\"{chunk_offsets[chunk]}-{vertices_3d_length}\"\n",
    "    intensities_range = f\"{chunk_offsets[chunk]+vertices_3d_length}-{intensities_length}\"\n",
    "\n",
    "    row = {\n",
    "        \"x_min\": 0,\n",
    "        \"y_min\": 0,\n",
    "        \"z_min\": 0,\n",
    "        \"x_max\": 1,\n",
    "        \"y_max\": 1,\n",
    "        \"z_max\": 1,\n",
    "        \"instances\": [\n",
    "            {\n",
    "                \"vertices_3d_binary_property_url\": f\"{server_root}/chunk-{chunk}:{vertices_range}\",\n",
    "                \"vertices_3d_additional_data\": {\n",
    "                    \"intensity_binary_property_url\": f\"{server_root}/chunk-{chunk}:{intensities_range}\"\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    chunk_offsets[chunk] += vertices_3d_length\n",
    "    chunk_offsets[chunk] += intensities_length\n",
    "    lookup_table[f\"chunk-{chunk}\"][intensities_range] = {\"sample\": i, \"attribute\": \"intensities\"}\n",
    "    lookup_table[f\"chunk-{chunk}\"][vertices_range] = {\"sample\": i, \"attribute\": \"vertices_2d\"}\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56627f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lookup_table_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(lookup_table_path, \"w\") as f:\n",
    "    json.dump(lookup_table, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fa2439",
   "metadata": {},
   "source": [
    "## Write the Table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = tlc.Geometry3DSchema(\n",
    "    include_3d_vertices=True,\n",
    "    per_vertex_schemas={\n",
    "        \"intensity\": tlc.Float32ListSchema()\n",
    "    },\n",
    "    is_bulk_data=True,  # This is what sets up the \"sibling\" paths with the \"_binary_property_url\" suffix\n",
    ")\n",
    "\n",
    "table_writer = tlc.TableWriter(\n",
    "    table_name=\"pre-externalized-table\",\n",
    "    dataset_name=\"pre-externalized-dataset\",\n",
    "    project_name=\"pre-externalized-project\",\n",
    "    description=\"Pre-externalized table\",\n",
    "    column_schemas={\"vertices\": schema},  # We use the same schema as before\n",
    "    if_exists=\"rename\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd7151",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    table_writer.add_row({\"vertices\": row})\n",
    "\n",
    "table = table_writer.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2dfcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
