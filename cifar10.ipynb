{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff0e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYPI_USERNAME'] = ''\n",
    "os.environ['PYPI_PASSWORD'] = ''\n",
    "\n",
    "!git clone https://github.com/3lc-ai/notebook-examples.git\n",
    "\n",
    "%run notebook-examples/tlc-install.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b136986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYPI_USERNAME'] = ''\n",
    "os.environ['PYPI_PASSWORD'] = ''\n",
    "\n",
    "!git clone https://github.com/3lc-ai/notebook-examples.git\n",
    "\n",
    "%run notebook-examples/tlc-install.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aeaddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYPI_USERNAME'] = ''\n",
    "os.environ['PYPI_PASSWORD'] = ''\n",
    "\n",
    "!git clone https://github.com/3lc-ai/notebook-examples.git\n",
    "\n",
    "%run notebook-examples/tlc-install.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab5152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYPI_USERNAME'] = ''\n",
    "os.environ['PYPI_PASSWORD'] = ''\n",
    "\n",
    "!git clone https://github.com/3lc-ai/notebook-examples.git\n",
    "\n",
    "%run notebook-examples/tlc-install.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d26079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYPI_USERNAME'] = ''\n",
    "os.environ['PYPI_PASSWORD'] = ''\n",
    "\n",
    "!git clone https://github.com/3lc-ai/notebook-examples.git\n",
    "\n",
    "%run notebook-examples/tlc-install.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d500ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYPI_USERNAME'] = ''\n",
    "os.environ['PYPI_PASSWORD'] = ''\n",
    "\n",
    "!git clone https://github.com/3lc-ai/notebook-examples.git\n",
    "\n",
    "%run notebook-examples/tlc-install.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969672db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYPI_USERNAME'] = ''\n",
    "os.environ['PYPI_PASSWORD'] = ''\n",
    "\n",
    "!git clone https://github.com/3lc-ai/notebook-examples.git\n",
    "\n",
    "%run notebook-examples/tlc-install.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "TRAIN_BATCH_SIZE=32\n",
    "TEST_BATCH_SIZE=32\n",
    "LR=0.01       # Starting learning rate\n",
    "LR_GAMMA=0.9  # Exponential decay factor of learning rate (lr = LR * LR_GAMMA ^ epoch)\n",
    "MODEL_NAME=\"resnet18\"\n",
    "PRETRAINED=True\n",
    "DEVICE='cuda'\n",
    "NUM_WORKERS=4\n",
    "PIN_MEMORY=True\n",
    "# Dropout\n",
    "DROP_RATE=0.2\n",
    "DROP_PATH_RATE=0.2\n",
    "DATASET_PATH=\"/datasets/cifar10\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import timm\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=DATASET_PATH, train=True, download=True, transform=train_transforms)\n",
    "val_dataset = torchvision.datasets.CIFAR10(root=DATASET_PATH, train=False, transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, pin_memory=PIN_MEMORY, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    MODEL_NAME,\n",
    "    pretrained=PRETRAINED, \n",
    "    num_classes=len(classes), \n",
    "    drop_rate=DROP_RATE, \n",
    "    drop_path_rate=DROP_PATH_RATE\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=LR_GAMMA)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, scaler):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    return train_loss / total, 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return val_loss / total, 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_dataloader, criterion, optimizer, scaler)\n",
    "    val_loss, val_acc = validate(model, val_dataloader, criterion)\n",
    "\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.2f}%, Val Loss: {:.4f}, Val Acc: {:.2f}%, lr: {:.6f}'\n",
    "          .format(epoch+1, EPOCHS, train_loss, train_acc, val_loss, val_acc, lr_scheduler.get_last_lr()[0]))\n",
    "          \n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "5cf2cddba5a67a3ba4d2bbe409c69f8c3011f2684771111141abcd7c067c6336"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
