{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning a classifier using bounding box data from a 3LC Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will fine-tune a classifier using bounding box data from a 3LC `Table`.\n",
    "\n",
    "We will load the COCO128 table from an earlier notebook and use it to create a\n",
    "`torch.utils.Dataset` of bounding box crops. These cropped images will be used to\n",
    "fine-tune a classifier. In a later tutorial, we will use this trained model to\n",
    "generate embeddings and predicted labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tlc\n",
    "\n",
    "from tlc_tools.augment_bbs.finetune_on_crops import train_model\n",
    "from tlc_tools.common import infer_torch_device\n",
    "from tlc_tools.split import split_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "MODEL_CHECKPOINT = \"../../../transient_data/seg_classifier.pth\"\n",
    "MODEL_NAME = \"efficientnet_b0\"\n",
    "INCLUDE_BACKGROUND = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = infer_torch_device()\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input Table\n",
    "\n",
    "We will reuse the table created in the notebook [create-table-from-coco.ipynb](../../1-create-tables/create-table-from-coco.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m3lc: \u001b[0mLoaded project alias configuration from C:/Users/gudbrand/AppData/Local/3LC/3LC/projects/3LC Tutorials/default_aliases.3lc.yaml\n"
     ]
    }
   ],
   "source": [
    "input_table = tlc.Table.from_names(\n",
    "    \"initial-segmentation\",\n",
    "    \"COCO128\",\n",
    "    \"3LC Tutorials\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using table EditedTable(project_name=\"3LC Tutorials\", dataset_name=\"COCO128\", name=\"train_0003\", row_count=103) for training\n",
      "Using table EditedTable(project_name=\"3LC Tutorials\", dataset_name=\"COCO128\", name=\"val_0003\", row_count=25) for validation\n"
     ]
    }
   ],
   "source": [
    "# Create splits for training and validation\n",
    "splits = split_table(input_table, {\"train\": 0.8, \"val\": 0.2})\n",
    "\n",
    "train_table = splits[\"train\"]\n",
    "val_table = splits[\"val\"]\n",
    "\n",
    "print(f\"Using table {train_table} for training\")\n",
    "print(f\"Using table {val_table} for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Instance configuration for training:\n",
      "  Instance column: segmentations\n",
      "  Instance type: segmentation_masks\n",
      "  Label column path: instance_properties.label\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Label map not found in table at path: instance_properties.label",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtlc_tools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InstanceConfig\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model, checkpoint_path = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_table_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_table\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_table_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_table\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_CHECKPOINT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_background\u001b[49m\u001b[43m=\u001b[49m\u001b[43mINCLUDE_BACKGROUND\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use more workers in a non-notebook environment\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstance_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mInstanceConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstance_column\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msegmentations\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msegmentation_masks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_column_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstance_properties.label\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Project\\notebook-examples\\src\\tlc_tools\\augment_bbs\\finetune_on_crops.py:90\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(train_table_url, val_table_url, model_name, model_checkpoint, epochs, batch_size, include_background, x_max_offset, y_max_offset, x_scale_range, y_scale_range, num_workers, label_column_path, instance_config)\u001b[39m\n\u001b[32m     88\u001b[39m label_map = train_table.get_simple_value_map(resolved_label_column_path)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m label_map:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLabel map not found in table at path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_label_column_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     91\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLabel map: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_map\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# Create label mappings for training and validation\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Label map not found in table at path: instance_properties.label"
     ]
    }
   ],
   "source": [
    "from tlc_tools.common import InstanceConfig\n",
    "\n",
    "\n",
    "model, checkpoint_path = train_model(\n",
    "    train_table_url=train_table.url,\n",
    "    val_table_url=val_table.url,\n",
    "    model_checkpoint=MODEL_CHECKPOINT,\n",
    "    epochs=1,\n",
    "    include_background=INCLUDE_BACKGROUND,\n",
    "    num_workers=0,  # Use more workers in a non-notebook environment\n",
    "    instance_config=InstanceConfig(\n",
    "        instance_column=\"segmentations\",\n",
    "        instance_type=\"segmentation_masks\",\n",
    "        label_column_path=\"segmentations.instance_properties.label\",\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
