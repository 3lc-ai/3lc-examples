{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Table from PyTorch Dataset\n",
    "\n",
    "Convert a PyTorch Dataset into a 3LC Table using the built-in conversion method.\n",
    "\n",
    "![img](../images/from-torch.png)\n",
    "\n",
    "<!-- Tags: [\"pytorch\", \"cifar-10\"] -->\n",
    "\n",
    "Many ML practitioners already have PyTorch datasets for their projects. Converting them to 3LC Tables allows you to leverage 3LC's data analysis and visualization capabilities while maintaining compatibility with your existing PyTorch training pipelines.\n",
    "\n",
    "We use `tlc.Table.from_torch_dataset()` to convert any map-style PyTorch Dataset to a 3LC Table. The method iterates through the dataset, converts samples to 3LC's format, and can either infer the schema from the first sample or use a provided schema.\n",
    "\n",
    "Note that this method requires map-style datasets (not iterable) and needs access to the dataset length. It's not suitable for stochastic or infinite datasets since it requires a complete iteration to create the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "TMP_PATH = \"../../transient_data\"  # A folder to store temporary data (zipped CIFAR images)\n",
    "MAX_SAMPLES = None  # Limit the number of samples per split (None for all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q 3lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tlc\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CIFAR10(TMP_PATH, train=True, download=True)\n",
    "val_dataset = CIFAR10(TMP_PATH, train=False)\n",
    "\n",
    "cifar_classes = train_dataset.classes\n",
    "\n",
    "if MAX_SAMPLES is not None:\n",
    "    train_dataset = Subset(train_dataset, range(min(MAX_SAMPLES, len(train_dataset))))\n",
    "    val_dataset = Subset(val_dataset, range(min(MAX_SAMPLES, len(val_dataset))))\n",
    "\n",
    "# The \"structure\" of the table is a representation of an individual sample in the dataset.\n",
    "# Here, we define the structure of the table to be A tuple containing a image and a label.\n",
    "structure = (tlc.PILImage(\"Image\"), tlc.CategoricalLabel(\"Label\", classes=cifar_classes))\n",
    "\n",
    "train_table = tlc.Table.from_torch_dataset(\n",
    "    train_dataset,\n",
    "    structure=structure,\n",
    "    project_name=\"3LC Tutorials - CIFAR-10\",\n",
    "    dataset_name=\"CIFAR-10-train\",\n",
    "    table_name=\"initial\",\n",
    ")\n",
    "\n",
    "val_table = tlc.Table.from_torch_dataset(\n",
    "    val_dataset,\n",
    "    structure=structure,\n",
    "    project_name=\"3LC Tutorials - CIFAR-10\",\n",
    "    dataset_name=\"CIFAR-10-val\",\n",
    "    table_name=\"initial\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
