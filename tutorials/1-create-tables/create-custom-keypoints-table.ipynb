{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Create a custom keypoints table\n",
    "\n",
    "In this tutorial, we will create a custom keypoints table from the [Animal Pose Dataset](https://sites.google.com/view/animal-pose/), originally introduced in the paper [Cross-Domain Adaptation for Animal Pose Estimation](https://doi.org/10.48550/arXiv.1908.05806).\n",
    "\n",
    "We will use a version of the dataset hosted on Kaggle. The annotations are in a COCO-like json format, which we will extract manually and convert to the 3LC keypoint format.\n",
    "\n",
    "`Cao, Jinkun, Hongyang Tang, Hao-Shu Fang, Xiaoyong Shen, Cewu Lu, and Yu-Wing Tai.  \n",
    "*Cross-Domain Adaptation for Animal Pose Estimation*. arXiv preprint [arXiv:1908.05806](https://arxiv.org/abs/1908.05806), 2019.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"3LC Tutorials\"\n",
    "DATASET_NAME = \"AnimalPose\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tlc\n",
    "from PIL import Image\n",
    "from tlc.core import KeypointHelper\n",
    "from tlc.core.builtins.schemas import ImageUrlSchema, Keypoints2DSchema\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "The following cell downloads the dataset from Kaggle. The dataset requires 350MB of disk space, as well as a [Kaggle account](https://www.kaggle.com/docs/api#authentication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "DATASET_ROOT = kagglehub.dataset_download(\"bloodaxe/animal-pose-dataset\")\n",
    "DATASET_ROOT = Path(DATASET_ROOT)\n",
    "\n",
    "print(\"Path to dataset files:\", DATASET_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_FILE = DATASET_ROOT / \"keypoints.json\"\n",
    "IMAGE_ROOT = DATASET_ROOT / \"images\" / \"images\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Load annotations / metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the dataset root as a project URL alias - this enables to easily share the table or move the source data\n",
    "tlc.register_project_url_alias(\"ANIMAL_POSE_DATA\", DATASET_ROOT, project=PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ANNOTATIONS_FILE) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Load metadata from the annotations file\n",
    "NUM_KEYPOINTS = 20\n",
    "KEYPOINT_NAMES = data[\"categories\"][0][\"keypoints\"]\n",
    "CLASSES = {cat[\"id\"]: cat[\"name\"] for cat in data[\"categories\"]}\n",
    "SKELETON = np.array(data[\"categories\"][0][\"skeleton\"]).reshape(-1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Some metadata is not stored in the annotations file, so we need to define it manually.\n",
    " These values were taken from the SuperGradients example notebook [YoloNAS_Pose_Fine_Tuning_Animals_Pose_Dataset](https://github.com/Deci-AI/super-gradients/blob/master/notebooks/YoloNAS_Pose_Fine_Tuning_Animals_Pose_Dataset.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "OKS_SIGMAS = [0.07] * 20\n",
    "FLIP_INDEXES = [1, 0, 2, 4, 3, 6, 5, 8, 7, 10, 9, 12, 11, 14, 13, 16, 15, 17, 18, 19]\n",
    "\n",
    "KEYPOINT_COLORS = [\n",
    "    [148, 0, 211],\n",
    "    [75, 0, 130],\n",
    "    [0, 0, 255],\n",
    "    [0, 255, 0],\n",
    "    [255, 255, 0],\n",
    "    [255, 165, 0],\n",
    "    [255, 69, 0],\n",
    "    [255, 0, 0],\n",
    "    [139, 0, 0],\n",
    "    [128, 0, 128],\n",
    "    [238, 130, 238],\n",
    "    [186, 85, 211],\n",
    "    [148, 0, 211],\n",
    "    [0, 255, 255],\n",
    "    [0, 128, 128],\n",
    "    [0, 0, 139],\n",
    "    [0, 0, 255],\n",
    "    [0, 255, 0],\n",
    "    [255, 69, 0],\n",
    "    [255, 20, 147],\n",
    "]\n",
    "\n",
    "EDGE_COLORS = [\n",
    "    [127, 0, 255],\n",
    "    [91, 56, 253],\n",
    "    [55, 109, 248],\n",
    "    [19, 157, 241],\n",
    "    [18, 199, 229],\n",
    "    [54, 229, 215],\n",
    "    [90, 248, 199],\n",
    "    [128, 254, 179],\n",
    "    [164, 248, 158],\n",
    "    [200, 229, 135],\n",
    "    [236, 199, 110],\n",
    "    [255, 157, 83],\n",
    "    [255, 109, 56],\n",
    "    [255, 56, 28],\n",
    "    [255, 0, 0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = data[\"annotations\"]\n",
    "images = data[\"images\"]\n",
    "\n",
    "row_data = {\n",
    "    \"image\": [],\n",
    "    \"keypoints_2d\": [],\n",
    "    \"image_id\": [],\n",
    "}\n",
    "\n",
    "# Pre-compute mapping from image_id to annotations for faster lookup\n",
    "image_id_2_anns = {}\n",
    "for ann in annotations:\n",
    "    image_id_2_anns.setdefault(str(ann[\"image_id\"]), []).append(ann)\n",
    "\n",
    "for image_id, image_path in tqdm(images.items(), total=len(images), desc=\"Loading annotations\"):\n",
    "    image_path = Path(IMAGE_ROOT) / image_path\n",
    "    row_data[\"image_id\"].append(image_id)\n",
    "    if not image_path.exists():\n",
    "        print(f\"Image {image_path} does not exist\")\n",
    "        continue\n",
    "\n",
    "    with Image.open(image_path) as img:\n",
    "        width, height = img.size\n",
    "\n",
    "    anns = image_id_2_anns[image_id]\n",
    "    keypoints = {\n",
    "        \"x_max\": width,\n",
    "        \"y_max\": height,\n",
    "        \"instances\": [],\n",
    "        \"instances_additional_data\": {\n",
    "            \"label\": [],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    for ann in anns:\n",
    "        kpts = np.array(ann[\"keypoints\"])[:, :2].reshape(-1).tolist()\n",
    "        visibilities = np.array(ann[\"keypoints\"])[:, 2].tolist()\n",
    "        bb = {\"x_min\": ann[\"bbox\"][0], \"y_min\": ann[\"bbox\"][1], \"x_max\": ann[\"bbox\"][2], \"y_max\": ann[\"bbox\"][3]}\n",
    "        label = ann[\"category_id\"]\n",
    "\n",
    "        keypoints[\"instances\"].append(\n",
    "            {\n",
    "                \"vertices_2d\": kpts,\n",
    "                \"vertices_2d_additional_data\": {\n",
    "                    \"visibilities\": visibilities,\n",
    "                },\n",
    "                \"bbs_2d\": [bb],\n",
    "            }\n",
    "        )\n",
    "        keypoints[\"instances_additional_data\"][\"label\"].append(label)\n",
    "\n",
    "    row_data[\"image\"].append(tlc.Url(image_path).to_relative().to_str())  # Url.to_relative applies aliases\n",
    "    row_data[\"keypoints_2d\"].append(keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Keypoints2DSchema accepts attributes per point/line. These will be used\n",
    "# when visualizing the table in the 3LC Dashboard.\n",
    "\n",
    "\n",
    "def rgb_tuple_to_hex(rgb) -> str:\n",
    "    return \"#\" + \"\".join(f\"{c:02X}\" for c in rgb)\n",
    "\n",
    "\n",
    "LINE_ATTRIBUTES = [tlc.MapElement(internal_name=\"edge\", display_color=rgb_tuple_to_hex(color)) for color in EDGE_COLORS]\n",
    "\n",
    "KEYPOINT_ATTRIBUTES = [\n",
    "    tlc.MapElement(internal_name=kpt_name, display_color=rgb_tuple_to_hex(color))\n",
    "    for kpt_name, color in zip(KEYPOINT_NAMES, KEYPOINT_COLORS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience, the schema for the keypoints column also stores metadata\n",
    "# relevant to training: oks_sigmas and flip_indices.\n",
    "\n",
    "keypoints_schema = Keypoints2DSchema(\n",
    "    num_keypoints=NUM_KEYPOINTS,\n",
    "    classes=CLASSES,\n",
    "    lines=SKELETON,\n",
    "    line_attributes=LINE_ATTRIBUTES,\n",
    "    point_attributes=KEYPOINT_ATTRIBUTES,\n",
    "    include_per_point_visibilities=True,\n",
    "    flip_indices=FLIP_INDEXES,\n",
    "    oks_sigmas=OKS_SIGMAS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = tlc.TableWriter(\n",
    "    table_name=\"initial\",\n",
    "    dataset_name=DATASET_NAME,\n",
    "    project_name=PROJECT_NAME,\n",
    "    column_schemas={\"image\": ImageUrlSchema(), \"keypoints_2d\": keypoints_schema},\n",
    "    if_exists=\"rename\",\n",
    ")\n",
    "tw.add_batch(row_data)\n",
    "table = tw.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Inspect the table\n",
    "\n",
    "We can use the `KeypointHelper` class to extract various geometric information from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the oks sigmas from the table\n",
    "KeypointHelper.get_oks_sigmas_from_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the flip indices from the table\n",
    "KeypointHelper.get_flip_indices_from_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the skeleton from the table\n",
    "KeypointHelper.get_lines_from_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the keypoint attributes from the table\n",
    "KeypointHelper.get_keypoint_attributes_from_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the line attributes from the table\n",
    "KeypointHelper.get_line_attributes_from_table(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "test_marks": [
   "dependent"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
