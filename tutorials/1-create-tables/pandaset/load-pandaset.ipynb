{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Load PandaSet\n",
    "\n",
    "This notebook shows how to load the PandaSet dataset into a 3LC Table. This involves preparing point clouds, cuboid and semantic segmentation data, and writing them using the [bulk data pattern](https://docs.3lc.ai/3lc/latest/tutorials/geometry/bulk_data.html#bulk-data-tutorial). For details on the ingestion process, see the [loading script](./load_pandaset.py)\n",
    "\n",
    "Running this notebook requires the [PandaSet DevKit](https://github.com/scaleapi/pandaset-devkit/blob/master/README.md), which can be installed as an extra to this repo: \n",
    "\n",
    "```bash\n",
    "pip install -e .[pandaset]\n",
    "```\n",
    "\n",
    "The dataset can be downloaded from [HuggingFace](https://huggingface.co/datasets/georghess/pandaset). If you have already downloaded `pandaset.zip`, ensure the dataset root below points to the unzipped pandaset directory.\n",
    "\n",
    "If not, the notebook will download `pandaset.zip` and unzip it into the dataset root directory. This requires authentication with HuggingFace, for example by setting the `HF_TOKEN` environment variable.\n",
    "\n",
    "> ⚠️ Storage requirements\n",
    ">\n",
    "> The unzipped dataset is ~42GB, and ingesting all sequencesinto 3LC will\n",
    "> require another 50GB of disk space. Ensure you have enough free space before\n",
    "> running the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"3LC Tutorials\"\n",
    "DATASET_NAME = \"pandaset\"\n",
    "TABLE_NAME = \"pandaset\"\n",
    "DATA_PATH = \"../../../data\"\n",
    "DATASET_ROOT = \"D:/Data/pandaset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from load_pandaset import load_pandaset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = Path(DATASET_ROOT)\n",
    "\n",
    "if not DATASET_ROOT.exists():\n",
    "    import zipfile\n",
    "\n",
    "    from huggingface_hub import hf_hub_download\n",
    "\n",
    "    print(\"Downloading dataset from HuggingFace\")\n",
    "    hf_hub_download(\n",
    "        repo_id=\"georghess/pandaset\",\n",
    "        repo_type=\"dataset\",\n",
    "        filename=\"pandaset.zip\",\n",
    "        local_dir=DATASET_ROOT.parent.absolute().as_posix(),\n",
    "    )\n",
    "\n",
    "    with zipfile.ZipFile(f\"{DATASET_ROOT.parent}/pandaset.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(DATASET_ROOT.parent)\n",
    "else:\n",
    "    print(f\"Dataset root {DATASET_ROOT} already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Create Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = load_pandaset(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    table_name=TABLE_NAME,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    project_name=PROJECT_NAME,\n",
    "    data_path=DATA_PATH,\n",
    "    max_frames=None,\n",
    "    max_sequences=None,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9",
   "test_marks": [
    "slow", 
    "dependent"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
