{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Semantic Segmentation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will import the LIACi (Lifecycle Inspection, Analysis and\n",
    "Condition information) Semantic Segmentation Dataset for Underwater Ship\n",
    "Inspections, introduced in\n",
    "[this](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9998080) paper.\n",
    "\n",
    "The dataset contains roughly 2000 images of underwater ship hulls, together with\n",
    "corresponding annotations. The dataset contains both COCO-style annotations\n",
    "(bounding boxes and segmentation polygons) and pixel-wise annotations stored as\n",
    "single-channel bitmap images.\n",
    "\n",
    "In this notebook, we will import three different `tlc.Table`s from the dataset,\n",
    "in order to showcase different ways of working with annotated image dat in 3LC:\n",
    "\n",
    "1. `tlc.Table.from_coco()` to import the COCO-style bounding box annotations\n",
    "   (NOTE: 3LC does not yet support segmentation polygons, support for this is\n",
    "   right around the corner)\n",
    "2. `tlc.Table.from_torch_dataset()` using a custom torch dataset where the mask\n",
    "   images from all classes are merged into a single segmentation mask\n",
    "3. `tlc.Table.from_torch_dataset()` using a custom torch dataset which returns all\n",
    "   the 10 masks as separate elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"3LC Tutorials\"\n",
    "DATASET_NAME = \"LIACI\"\n",
    "\n",
    "INSTALL_DEPENDENCIES = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if INSTALL_DEPENDENCIES:\n",
    "    %pip --quiet install 3lc\n",
    "    %pip --quiet install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tlc\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from colorsys import hls_to_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "The dataset is available for download from the [official website](https://data.sintef.no/product/details/dp-9e112cec-3a59-4b58-86b3-ecb1f2878c60), and must be downloaded and extracted to a local directory manually.\n",
    "\n",
    "The dataset is stored in the following layout: \n",
    "\n",
    "```\n",
    "LIACi_dataset_pretty\n",
    "│\n",
    "├── images\n",
    "│   ├── image_0001.jpg\n",
    "│   ├── image_0002.jpg\n",
    "│   ├── image_0003.jpg\n",
    "│   └── ...\n",
    "│\n",
    "├── masks\n",
    "│   ├── anode\n",
    "│   │   ├── image_0001.bmp\n",
    "│   │   ├── image_0002.bmp\n",
    "│   │   ├── image_0003.bmp\n",
    "│   │   └── ...\n",
    "│   ├── bilge_keel\n",
    "│   ├── corrosion\n",
    "│   ├── defect\n",
    "│   ├── marine_growth\n",
    "│   ├── over_board_valves\n",
    "│   ├── paint_peel\n",
    "│   ├── propeller\n",
    "│   ├── saliency\n",
    "│   ├── sea_chest_grating\n",
    "│   ├── segmentation\n",
    "│   └── ship_hull\n",
    "│\n",
    "├── coco-annotations.json\n",
    "├── train_test_split.csv\n",
    "...\n",
    "```\n",
    "\n",
    "In other words, there is a single binary mask for each class for each image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Replace with your own path, after downloading and extracting the dataset\n",
    "DATASET_ROOT = \"C:/Data/LIACi_dataset_pretty\"\n",
    "\n",
    "tlc.register_url_alias(\"LIACI_DATASET_ROOT\", DATASET_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Import COCO-style Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_from_coco = tlc.Table.from_coco(\n",
    "    annotations_file=f\"{DATASET_ROOT}/coco-labels.json\",\n",
    "    image_folder=f\"{DATASET_ROOT}/images\",\n",
    "    project_name=PROJECT_NAME,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    table_name=\"coco\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Import Merged Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read out the value map from the first table:\n",
    "value_map: dict[float, tlc.MapElement] = table_from_coco.get_value_map(\"bbs.bb_list.label\")\n",
    "\n",
    "# Create a new mapping from directory name to category id:\n",
    "dir_2_category_id = {map_item.internal_name: int(value) for value, map_item in value_map.items()}\n",
    "\n",
    "# Rename the \"over_board_valve\" key to \"over_board_valves\", as the COCO category and the folder name differ:\n",
    "dir_2_category_id[\"over_board_valves\"] = dir_2_category_id[\"over_board_valve\"]\n",
    "del dir_2_category_id[\"over_board_valve\"]\n",
    "print(dir_2_category_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some helpers for updating the table's value map:\n",
    "\n",
    "def generate_hsi_colors(num_colors=10):\n",
    "    \"\"\"Generate a list of distinct colors in HSI space.\"\"\"\n",
    "    colors = []\n",
    "    saturation = 1.0\n",
    "    intensity = 0.7\n",
    "    hues = np.linspace(0, 1, num_colors, endpoint=False)\n",
    "    for hue in hues:\n",
    "        rgb = hls_to_rgb(hue, intensity, saturation)\n",
    "        colors.append(rgb_to_hex(rgb))\n",
    "    return colors\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    \"\"\"Convert an RGB tuple to a hex string.\"\"\"\n",
    "    return '#{:02x}{:02x}{:02x}'.format(int(rgb[0] * 255), int(rgb[1] * 255), int(rgb[2] * 255))\n",
    "\n",
    "\n",
    "colors = generate_hsi_colors(num_colors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some colors to the value map:\n",
    "for ind, map_element in enumerate(value_map.values()):\n",
    "    map_element.display_color = colors[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a torch Dataset returning (image, merged_mask) pairs:\n",
    "class LIACIDataset(Dataset):\n",
    "    def __init__(self, root, inverse_value_map):\n",
    "        self.root = root\n",
    "        self.inverse_value_map = inverse_value_map\n",
    "        image_folder = f\"{root}/images\"\n",
    "        self.image_files = os.listdir(image_folder)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.image_files[idx]\n",
    "        image_path = f\"{self.root}/images/{image_file}\"\n",
    "        image = Image.open(image_path)\n",
    "        mask = self._make_mask(image_file.replace(\".jpg\", \".bmp\"))\n",
    "        return image, mask\n",
    "\n",
    "    def _make_mask(self, image_file) -> Image:\n",
    "        # Merge all 10 binary masks into a single multiclass mask for this image\n",
    "        # Create an empty array for the categorical mask, initialized to 0 (background)\n",
    "        mask_shape = None\n",
    "        merged_mask = None\n",
    "\n",
    "        # Iterate over all categories\n",
    "        for category, category_id in self.inverse_value_map.items():\n",
    "            # Build the path to the current category mask\n",
    "            category_mask_path = f\"{self.root}/masks/{category}/{image_file}\"\n",
    "\n",
    "            # Open the binary mask for this category\n",
    "            category_mask = Image.open(category_mask_path)\n",
    "\n",
    "            # Convert the category mask to a numpy array\n",
    "            category_mask_array = np.array(category_mask)\n",
    "\n",
    "            # Ensure that the merged mask is initialized only once, with the correct shape\n",
    "            if mask_shape is None:\n",
    "                mask_shape = category_mask_array.shape\n",
    "                merged_mask = np.zeros(mask_shape, dtype=np.uint8)\n",
    "\n",
    "            # Assign the category ID to the merged mask wherever the binary mask is 1\n",
    "            merged_mask[category_mask_array == 1] = category_id\n",
    "\n",
    "        # Convert the merged mask back to a PIL Image\n",
    "        categorical_mask = Image.fromarray(merged_mask)\n",
    "\n",
    "        return categorical_mask\n",
    "\n",
    "\n",
    "dataset = LIACIDataset(DATASET_ROOT, dir_2_category_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `tlc.Table`. \n",
    "\n",
    "Since this table will contain images that are generated on-the-fly, and not\n",
    "backed by a file on disk, images will be written in the Table's \"bulk_data_url\"\n",
    "field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_mask_table = tlc.Table.from_torch_dataset(\n",
    "    dataset,\n",
    "    (tlc.PILImage(\"image\"), tlc.SegmentationPILImage(\"segmentation_map\", classes=value_map)),\n",
    "    project_name=PROJECT_NAME,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    table_name=\"merged-masks\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the location of the first merged mask file, relative to the table URL.\n",
    "tlc.Url(merged_mask_table.table_rows[0][\"segmentation_map\"]).to_relative(merged_mask_table.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3: Import Separate Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIACIDatasetV2(Dataset):\n",
    "    def __init__(self, root, inverse_value_map):\n",
    "        self.root = root\n",
    "        self.inverse_value_map = inverse_value_map\n",
    "        image_folder = f\"{root}/images\"\n",
    "        self.image_files = os.listdir(image_folder)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.image_files[idx]\n",
    "        image_path = f\"{self.root}/images/{image_file}\"\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        masks = (\n",
    "            Image.open(f\"{self.root}/masks/{label}/{image_file.replace('.jpg', '.bmp')}\")\n",
    "            for label in self.inverse_value_map.keys()\n",
    "        )\n",
    "        return image, *masks\n",
    "\n",
    "\n",
    "dataset = LIACIDatasetV2(DATASET_ROOT, dir_2_category_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `tlc.Table`.\n",
    "\n",
    "This table will contain one \"image\" column for the original image, and 10 \"mask\"\n",
    "columns, containing the binary masks for each class. Since the masks are backed\n",
    "by files on disk, the paths to the existing mask files are stored in the \"mask\"\n",
    "columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_structures = (\n",
    "    tlc.SegmentationPILImage(\n",
    "        f\"{label.internal_name}_mask\",\n",
    "        classes={0.0: tlc.MapElement(\"background\"), 255.0: label},\n",
    "    )\n",
    "    for label in value_map.values()\n",
    ")\n",
    "structure = (tlc.PILImage(\"image\"), *mask_structures)\n",
    "\n",
    "separate_masks_table = tlc.Table.from_torch_dataset(\n",
    "    dataset,\n",
    "    structure,\n",
    "    project_name=PROJECT_NAME,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    table_name=\"separate-masks\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe that the table data contains direct references to the original masks\n",
    "separate_masks_table.table_rows[0][\"paint_peel_mask\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
