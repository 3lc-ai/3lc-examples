{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggle competitions download -c sartorius-cell-instance-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycocotools.mask as mask_utils\n",
    "import tlc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"SEGMENTATION\"\n",
    "DATASET_NAME = \"SARTORIUS_CELL_INSTANCE_SEGMENTATION_TRAIN\"\n",
    "TABLE_NAME = \"initial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = Path(\"C:/Data/sartorius-cell-instance-segmentation\")\n",
    "assert DATASET_ROOT.exists(), f\"Dataset root {DATASET_ROOT} does not exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlc.register_url_alias(\"SARTORIUS_CELL_INSTANCE_SEGMENTATION_TRAIN\", DATASET_ROOT / \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlc.register_project_url_alias(\n",
    "    \"SARTORIUS_CELL_INSTANCE_SEGMENTATION_TRAIN\",\n",
    "    \"s3://3lc-projects/data/sartorius-cell-instance-segmentation/train\",\n",
    "    project=PROJECT_NAME,\n",
    "    root=\"s3://3lc-projects\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_file = DATASET_ROOT / \"train.csv\"\n",
    "assert train_csv_file.exists(), f\"Train CSV file {train_csv_file} does not exist\"\n",
    "\n",
    "train_df = pd.read_csv(train_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = set()\n",
    "\n",
    "for cell_type in train_df[\"cell_type\"]:\n",
    "    cell_types.add(cell_type)\n",
    "\n",
    "cell_types = list(cell_types)\n",
    "cell_types.sort()\n",
    "cell_types_to_index = {cell_type: index for index, cell_type in enumerate(cell_types)}\n",
    "\n",
    "print(cell_types_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group annotations by image_id\n",
    "image_annotations = {}\n",
    "\n",
    "for _, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    image_id = row[\"id\"]\n",
    "\n",
    "    if image_id not in image_annotations:\n",
    "        image_annotations[image_id] = {\n",
    "            \"width\": row[\"width\"],\n",
    "            \"height\": row[\"height\"],\n",
    "            \"sample_id\": row[\"sample_id\"],\n",
    "            \"image_path\": DATASET_ROOT / \"train\" / f\"{image_id}.png\",\n",
    "            \"annotations\": [],\n",
    "        }\n",
    "        # Verify image exists\n",
    "        assert image_annotations[image_id][\n",
    "            \"image_path\"\n",
    "        ].exists(), f\"Image {image_annotations[image_id]['image_path']} does not exist\"\n",
    "\n",
    "    # Add this annotation\n",
    "    annotation = {\n",
    "        \"cell_type\": row[\"cell_type\"],\n",
    "        \"cell_type_index\": cell_types_to_index[row[\"cell_type\"]],\n",
    "        \"segmentation\": list(map(int, row[\"annotation\"].split())),\n",
    "    }\n",
    "    image_annotations[image_id][\"annotations\"].append(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def starts_lengths_to_coco_rle(starts_lengths, image_height, image_width):\n",
    "    # Convert to numpy array and get starts/lengths\n",
    "    s = np.array(starts_lengths, dtype=int)\n",
    "    starts = s[0::2] - 1  # Convert from 1-based to 0-based indexing\n",
    "    lengths = s[1::2]\n",
    "\n",
    "    # Create binary mask\n",
    "    mask = np.zeros(image_height * image_width, dtype=np.uint8)\n",
    "    for start, length in zip(starts, lengths):\n",
    "        mask[start : start + length] = 1\n",
    "    mask = mask.reshape(image_height, image_width)\n",
    "\n",
    "    # Convert to COCO RLE format\n",
    "    rle = mask_utils.encode(np.asfortranarray(mask))\n",
    "    return rle[\"counts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now image_annotations contains all annotations grouped by image_id\n",
    "# We can process them further as needed:\n",
    "def annotations_to_3lc_format(image_annotations):\n",
    "    \"\"\"\n",
    "    Input format:\n",
    "    {\n",
    "        \"cell_type_index\": int,\n",
    "        \"segmentation\": list[int],\n",
    "        \"width\": int,\n",
    "        \"height\": int,\n",
    "    }\n",
    "\n",
    "    Output format:\n",
    "    {\n",
    "        \"image_height\": int,\n",
    "        \"image_width\": int,\n",
    "        \"rles\": list[bytes],\n",
    "        \"instance_properties\": {\n",
    "            \"cell_type\": list[int],\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    image_height = image_annotations[\"height\"]\n",
    "    image_width = image_annotations[\"width\"]\n",
    "\n",
    "    rles = []\n",
    "    cell_types = []\n",
    "\n",
    "    for annotation in image_annotations[\"annotations\"]:\n",
    "        rle = starts_lengths_to_coco_rle(annotation[\"segmentation\"], image_height, image_width)\n",
    "        rles.append(rle)\n",
    "        cell_types.append(annotation[\"cell_type_index\"])\n",
    "\n",
    "    return {\n",
    "        \"image_height\": image_height,\n",
    "        \"image_width\": image_width,\n",
    "        \"rles\": rles,\n",
    "        \"instance_properties\": {\n",
    "            \"cell_type\": cell_types,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "sample_ids = []\n",
    "image_paths = []\n",
    "segmentations = []\n",
    "\n",
    "for image_id, image_data in tqdm(image_annotations.items(), total=len(image_annotations)):\n",
    "    sample_ids.append(image_data[\"sample_id\"])\n",
    "    image_paths.append(tlc.Url(DATASET_ROOT / \"train\" / f\"{image_id}.png\").to_relative().to_str())\n",
    "    segmentations.append(annotations_to_3lc_format(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = {\n",
    "    \"sample_id\": sample_ids,\n",
    "    \"image\": image_paths,\n",
    "    \"segmentations\": segmentations,\n",
    "}\n",
    "\n",
    "table_schemas = {\n",
    "    \"image\": tlc.PILImage(\"image\"),\n",
    "    \"segmentations\": tlc.InstanceSegmentationMasks(\n",
    "        \"segmentations\",\n",
    "        instance_properties_structure={\n",
    "            \"cell_type\": tlc.CategoricalLabel(\"cell_type\", list(cell_types_to_index.keys()))\n",
    "        },\n",
    "    ).schema,\n",
    "}\n",
    "\n",
    "table = tlc.Table.from_dict(\n",
    "    table_data,\n",
    "    structure=table_schemas,\n",
    "    project_name=PROJECT_NAME,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    table_name=TABLE_NAME,\n",
    "    if_exists=\"rename\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.table_rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
