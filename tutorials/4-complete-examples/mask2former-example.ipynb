{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"3LC Tutorials\"\n",
    "DATASET_NAME = \"LIACI\"\n",
    "INSTANCE_SEGMENTATION_TABLE_NAME = \"instance-segmentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation, Mask2FormerImageProcessor\n",
    "\n",
    "# load Mask2Former fine-tuned on COCO instance segmentation\n",
    "processor: Mask2FormerImageProcessor = AutoImageProcessor.from_pretrained(\n",
    "    \"facebook/mask2former-swin-tiny-coco-instance\"\n",
    ")\n",
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-tiny-coco-instance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tlc_tools.common import infer_torch_device\n",
    "\n",
    "device = infer_torch_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Allocated: {torch.cuda.memory_allocated()/1024**2:.2f}MB\")\n",
    "        print(f\"Cached: {torch.cuda.memory_reserved()/1024**2:.2f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# image_folder = Path(r\"C:\\Users\\gudbrand\\OneDrive\\Bilder\\Bryllup\")\n",
    "image_folder = Path(r\"C:\\Data\\balloon\\train\")\n",
    "\n",
    "table = tlc.Table.from_image_folder(\n",
    "    image_folder,\n",
    "    include_label_column=False,\n",
    "    table_name=\"Balloons\",\n",
    "    dataset_name=\"Test\",\n",
    "    project_name=\"Test\",\n",
    "    # if_exists=\"overwrite\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_map = tlc.MapElement._construct_value_map(model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def table_map(sample):\n",
    "    image = sample  # sample is a PIL image\n",
    "\n",
    "    def get_correct_dimensions(image):\n",
    "        orientation = image.getexif().get(274, 1)  # 274 is the EXIF orientation tag\n",
    "        w, h = image.size\n",
    "\n",
    "        if orientation in [5, 6, 7, 8]:\n",
    "            return h, w\n",
    "        return w, h\n",
    "\n",
    "    # Store original image size before any processing\n",
    "    width, height = get_correct_dimensions(image)\n",
    "    img_array = np.array(image)\n",
    "    img_tensor = torch.from_numpy(img_array).permute(2, 0, 1)\n",
    "    # Check tensor dimensions - should be (C,H,W)\n",
    "    if len(img_tensor.shape) != 3:\n",
    "        raise ValueError(f\"Expected tensor with 3 dimensions (C,H,W), got shape {img_tensor.shape}\")\n",
    "    if img_tensor.shape[0] != 3:\n",
    "        raise ValueError(f\"Expected 3 channels, got {img_tensor.shape[0]}\")\n",
    "    return img_tensor, (width, height)\n",
    "\n",
    "\n",
    "table.clear_maps()\n",
    "table.map(table_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(batch):\n",
    "    images = batch[0]\n",
    "    inputs = processor(images=images.squeeze(0), return_tensors=\"pt\")\n",
    "\n",
    "    return dict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = tlc.Predictor(model, unpack_dicts=True, preprocess_fn=preprocessor, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_fn(batch, predictor_output):\n",
    "    _, (w, h) = batch\n",
    "    w = int(w)\n",
    "    h = int(h)\n",
    "\n",
    "    result = processor.post_process_instance_segmentation(\n",
    "        predictor_output.forward, target_sizes=[(h, w)], return_binary_maps=True\n",
    "    )[0]\n",
    "\n",
    "    masks = result[\"segmentation\"]\n",
    "    infos = result[\"segments_info\"]\n",
    "\n",
    "    labels = [i[\"label_id\"] for i in infos]\n",
    "    scores = [i[\"score\"] for i in infos]\n",
    "\n",
    "    # transposed = masks.cpu().numpy()\n",
    "    # if len(transposed.shape) == 2:  # Single mask case\n",
    "    #     transposed = np.expand_dims(transposed, axis=2)\n",
    "    # else:\n",
    "    #     transposed = transposed.transpose(1, 2, 0)\n",
    "    # transposed = transposed.astype(np.uint8)\n",
    "    def process_masks_efficiently(masks):\n",
    "        processed = []\n",
    "        # Process each mask individually\n",
    "        for i in range(masks.shape[-1]):  # Iterate over the last dimension\n",
    "            single_mask = masks[..., i]\n",
    "            single_mask = single_mask.astype(np.uint8)\n",
    "            processed.append(single_mask)\n",
    "\n",
    "        # Stack only at the end\n",
    "        return np.stack(processed, axis=-1)\n",
    "\n",
    "    # Use it like this:\n",
    "    if len(masks.shape) == 2:  # Single mask case\n",
    "        transposed = np.expand_dims(masks.cpu().numpy(), axis=2)\n",
    "    else:\n",
    "        transposed = masks.cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "    transposed = process_masks_efficiently(transposed)\n",
    "\n",
    "    # Allow final dimension to vary based on number of masks\n",
    "    # assert transposed.shape[0] == w and transposed.shape[1] == h,\n",
    "    # f\"Expected shape ({h}, {w}, N) but got {transposed.shape}\"\n",
    "    instances = {\n",
    "        \"image_height\": h,\n",
    "        \"image_width\": w,\n",
    "        \"masks\": transposed,\n",
    "        \"instance_properties\": {\"label\": labels, \"scores\": scores},\n",
    "    }\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return {\"predicted_masks\": [instances]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_collector = tlc.FunctionalMetricsCollector(\n",
    "    collect_fn,\n",
    "    column_schemas={\n",
    "        \"predicted_masks\": tlc.InstanceSegmentationMasks(\n",
    "            \"predicted_masks\",\n",
    "            instance_properties_structure={\n",
    "                \"label\": tlc.CategoricalLabel(\"label\", value_map),\n",
    "                \"scores\": tlc.IoU(\"scores\"),\n",
    "            },\n",
    "            is_prediction=True,\n",
    "        ),\n",
    "    },\n",
    "    compute_aggregates=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlc.collect_metrics(table, metrics_collector, predictor=predictor, collect_aggregates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = tlc.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.set_status_completed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.metrics_tables[-1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_type = tlc.InstanceSegmentationMasks(\n",
    "    \"segmentations\", instance_properties_structure={\"label\": tlc.CategoricalLabel(\"label\", value_map)}\n",
    ")\n",
    "\n",
    "column_added_table = table.add_column(\n",
    "    column_name=\"segmentations\",\n",
    "    values={\"image_height\": 0, \"image_width\": 0, \"instance_properties\": {\"label\": []}, \"rles\": []},\n",
    "    schema=sample_type.schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_added_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
