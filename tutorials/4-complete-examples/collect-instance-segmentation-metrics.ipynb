{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Instance Segmentation Metrics from Pretrained Model\n",
    "\n",
    "In this example, we will collect predicted instance segmentation masks from a pretrained model from the Hugging Face Hub.\n",
    "\n",
    "The model we will use is\n",
    "[Mask2Former](https://huggingface.co/docs/transformers/en/model_doc/mask2former),\n",
    "and the metrics will be collecting using the\n",
    "[`tlc.collect_metrics`](https://docs.3lc.ai/3lc/latest/apidocs/tlc/tlc.client.torch.metrics.collect.html#tlc.client.torch.metrics.collect.collect_metrics)\n",
    "function.\n",
    "\n",
    "Metrics will be collected on a Table of images from the COCO128 dataset, but any image folder can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation, Mask2FormerImageProcessor\n",
    "\n",
    "import tlc\n",
    "from tlc_tools.common import infer_torch_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"3LC Tutorials\"\n",
    "DATASET_NAME = \"Mask2Former Example\"\n",
    "TABLE_NAME = \"COCO128\"\n",
    "HF_MODEL_ID = \"facebook/mask2former-swin-tiny-coco-instance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model\n",
    "\n",
    "Load a small Mask2Former model fine-tuned on COCO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(HF_MODEL_ID)\n",
    "\n",
    "device = infer_torch_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor: Mask2FormerImageProcessor = AutoImageProcessor.from_pretrained(\n",
    "    HF_MODEL_ID,\n",
    "    use_fast=False,\n",
    "    do_rescale=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Table\n",
    "\n",
    "Create the Table to run inference on. Note we add an empty extra column for\n",
    "\"segmentations\", which can be used as a target for accepting predictions when\n",
    "analyzing the Run in the 3LC Dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = Path(\"../../data/coco128/images\").absolute()\n",
    "assert image_folder.exists(), f\"Image folder does not exist: {image_folder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a value map from the model's label mapping\n",
    "value_map = {k: tlc.MapElement(v) for k, v in model.config.id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tlc.Table.from_image_folder(\n",
    "    image_folder,\n",
    "    include_label_column=False,\n",
    "    table_name=TABLE_NAME,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    project_name=PROJECT_NAME,\n",
    "    extra_columns={\n",
    "        \"segmentations\": tlc.InstanceSegmentationMasks(\n",
    "            \"segmentations\",\n",
    "            instance_properties_structure={\n",
    "                \"label\": tlc.CategoricalLabel(\"label\", value_map),\n",
    "            },\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the Table for inference by converting the images to tensors and adding\n",
    "the original size of the image, which will be used to resize the predicted masks\n",
    "to the original size of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_map(sample):\n",
    "    img_tensor = T.ToTensor()(sample.convert(\"RGB\"))\n",
    "\n",
    "    inputs = image_processor(images=img_tensor, return_tensors=\"pt\")\n",
    "    inputs[\"pixel_values\"] = inputs[\"pixel_values\"].squeeze(0)\n",
    "    inputs[\"original_size\"] = torch.tensor([sample.height, sample.width])\n",
    "    return dict(inputs)\n",
    "\n",
    "\n",
    "table.map(table_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Metrics Collector\n",
    "\n",
    "Define the metrics collector function. This function will be called with a batch\n",
    "of images and the the outputs from the model. The function returns a dictionary\n",
    "of lists with the predicted masks in 3LC segmentation format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_fn(batch, predictor_output):\n",
    "    original_sizes = [(int(h), int(w)) for h, w in batch[\"original_size\"]]\n",
    "\n",
    "    results = image_processor.post_process_instance_segmentation(\n",
    "        predictor_output.forward,\n",
    "        target_sizes=original_sizes,\n",
    "        return_binary_maps=True,\n",
    "    )\n",
    "\n",
    "    predicted_instances = []\n",
    "\n",
    "    for result, (height, width) in zip(results, original_sizes):\n",
    "        masks = result[\"segmentation\"]\n",
    "        labels = [i[\"label_id\"] for i in result[\"segments_info\"]]\n",
    "        scores = [i[\"score\"] for i in result[\"segments_info\"]]\n",
    "\n",
    "        if masks is not None:\n",
    "            masks = (\n",
    "                np.expand_dims(masks.cpu().numpy(), axis=2)\n",
    "                if len(masks.shape) == 2\n",
    "                else masks.cpu().numpy().transpose(1, 2, 0)\n",
    "            )\n",
    "\n",
    "            masks = masks.astype(np.uint8)\n",
    "        else:\n",
    "            masks = np.zeros((0, height, width), dtype=np.uint8)\n",
    "\n",
    "        instances = {\n",
    "            \"image_height\": height,\n",
    "            \"image_width\": width,\n",
    "            \"masks\": masks,\n",
    "            \"instance_properties\": {\"label\": labels, \"score\": scores},\n",
    "        }\n",
    "        predicted_instances.append(instances)\n",
    "\n",
    "    return {\"predicted_masks\": predicted_instances}\n",
    "\n",
    "\n",
    "metrics_collector = tlc.FunctionalMetricsCollector(\n",
    "    collect_fn,\n",
    "    column_schemas={\n",
    "        \"predicted_masks\": tlc.InstanceSegmentationMasks(\n",
    "            \"predicted_masks\",\n",
    "            instance_properties_structure={\n",
    "                \"label\": tlc.CategoricalLabel(\"label\", value_map),\n",
    "                \"score\": tlc.IoU(\"score\"),\n",
    "            },\n",
    "            is_prediction=True,\n",
    "        ),\n",
    "    },\n",
    "    compute_aggregates=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Metrics\n",
    "\n",
    "Create a Run and collect the segmentation metrics from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = tlc.init(project_name=PROJECT_NAME, run_name=\"Collect Segmentation Metrics\")\n",
    "\n",
    "tlc.collect_metrics(\n",
    "    table,\n",
    "    metrics_collector,\n",
    "    model,\n",
    "    collect_aggregates=False,\n",
    "    dataloader_args={\"batch_size\": 4},\n",
    ")\n",
    "\n",
    "run.set_status_completed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
