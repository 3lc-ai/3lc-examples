{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Semantic Segmentation Dataset\n",
    "\n",
    "In this tutorial, we will import the LIACi Semantic Segmentation Dataset for\n",
    "Underwater Ship Inspections, introduced in\n",
    "[this](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9998080) paper.\n",
    "\n",
    "The dataset contains roughly 2000 images of underwater ship hulls, together with\n",
    "their corresponding annotations. The dataset contains both COCO-style\n",
    "annotations (bounding boxes and segmentation polygons) and pixel-wise\n",
    "annotations stored as single-channel bitmap images.\n",
    "\n",
    "We will import three different tables from the dataset, in order to showcase\n",
    "different ways of working with annotated image dat in 3LC:\n",
    "\n",
    "1. `tlc.Table.from_coco()` to import the COCO-style bounding box annotations\n",
    "   (NOTE: 3LC does not yet support segmentation polygons, support for this is\n",
    "   right around the corner)\n",
    "2. `tlc.Table.from_torch_dataset()` using a custom torch dataset where the mask\n",
    "   images from all classes are merged into a single segmentation mask\n",
    "3. `tlc.Table.from_torch_dataset()` using a custom torch dataset which returns all\n",
    "   the 10 masks as separate elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: inline-flex; align-items: center; gap: 10px;\">\n",
    "        <a href=\"https://colab.research.google.com/github/3lc-ai/3lc-examples/blob/main/tutorials/import-sintef-dataset.ipynb\"\n",
    "        target=\"_blank\"\n",
    "            style=\"background-color: transparent; text-decoration: none; display: inline-flex; align-items: center;\n",
    "            padding: 5px 10px; font-family: Arial, sans-serif;\"> <img\n",
    "            src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" style=\"height: 30px;\n",
    "            vertical-align: middle;box-shadow: none;\"/>\n",
    "        </a> <a href=\"https://github.com/3lc-ai/3lc-examples/blob/main/tutorials/import-sintef-dataset.ipynb\"\n",
    "            style=\"text-decoration: none; display: inline-flex; align-items: center; background-color: #ffffff; border:\n",
    "            1px solid #d1d5da; border-radius: 8px; padding: 2px 10px; color: #333; font-family: Arial, sans-serif;\">\n",
    "            <svg aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"octicon octicon-mark-github\" viewBox=\"0 0 16 16\"\n",
    "            width=\"20\" height=\"20\" fill=\"#333\"\n",
    "            style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible; margin-right:\n",
    "            8px;\">\n",
    "                <path d=\"M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2\n",
    "                0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0\n",
    "                0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16\n",
    "                1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51\n",
    "                1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68\n",
    "                1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z\"></path>\n",
    "            </svg> <span style=\"vertical-align: middle; color: #333;\">Open in GitHub</span>\n",
    "        </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"LIACI\"\n",
    "DATASET_NAME = \"LIACI\"\n",
    "\n",
    "INSTALL_DEPENDENCIES = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if INSTALL_DEPENDENCIES:\n",
    "    %pip --quiet install 3lc\n",
    "    %pip --quiet install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tlc\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from colorsys import hls_to_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "The dataset is available for download from the [official website](https://data.sintef.no/product/details/dp-9e112cec-3a59-4b58-86b3-ecb1f2878c60), and must be downloaded and extracted to a local directory manually.\n",
    "\n",
    "The dataset is stored in the following layout: \n",
    "\n",
    "```\n",
    "LIACi_dataset_pretty\n",
    "│\n",
    "├── images\n",
    "│   ├── image_0001.jpg\n",
    "│   ├── image_0002.jpg\n",
    "│   ├── image_0003.jpg\n",
    "│   └── ...\n",
    "│\n",
    "├── masks\n",
    "│   ├── anode\n",
    "│   │   ├── image_0001.bmp\n",
    "│   │   ├── image_0002.bmp\n",
    "│   │   ├── image_0003.bmp\n",
    "│   │   └── ...\n",
    "│   ├── bilge_keel\n",
    "│   ├── corrosion\n",
    "│   ├── defect\n",
    "│   ├── marine_growth\n",
    "│   ├── over_board_valves\n",
    "│   ├── paint_peel\n",
    "│   ├── propeller\n",
    "│   ├── saliency\n",
    "│   ├── sea_chest_grating\n",
    "│   ├── segmentation\n",
    "│   └── ship_hull\n",
    "│\n",
    "├── coco-annotations.json\n",
    "├── train_test_split.csv\n",
    "...\n",
    "```\n",
    "\n",
    "In other words, there is a single binary mask for each class for each image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"C:/Data/LIACi_dataset_pretty\"\n",
    "\n",
    "tlc.register_url_alias(\"LIACI_DATASET_ROOT\", DATASET_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Import COCO-style Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_from_coco = tlc.Table.from_coco(\n",
    "    annotations_file=f\"{DATASET_ROOT}/coco-labels.json\",\n",
    "    image_folder=f\"{DATASET_ROOT}/images\",\n",
    "    project_name=PROJECT_NAME,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    table_name=\"coco\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Import Merged Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read out the value_map from the first table:\n",
    "value_map = table_from_coco.get_value_map(\"bbs.bb_list.label\")\n",
    "\n",
    "# Create a new simplified value map, using a corrected label name:\n",
    "simple_value_map = {map_item.internal_name: int(value) for value, map_item in value_map.items()}\n",
    "# Rename the \"over_board_valve\" key to \"over_board_valves\", as the COCO category and the folder name differ:\n",
    "simple_value_map[\"over_board_valves\"] = simple_value_map[\"over_board_valve\"]\n",
    "del simple_value_map[\"over_board_valve\"]\n",
    "print(simple_value_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some helpers:\n",
    "\n",
    "def generate_hsi_colors(num_colors=10):\n",
    "    \"\"\"Generate a list of distinct colors in HSI space.\"\"\"\n",
    "    colors = []\n",
    "    saturation = 1.0\n",
    "    intensity = 0.7\n",
    "    hues = np.linspace(0, 1, num_colors, endpoint=False)\n",
    "    for hue in hues:\n",
    "        rgb = hls_to_rgb(hue, intensity, saturation)\n",
    "        colors.append(rgb_to_hex(rgb))\n",
    "    return colors\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    \"\"\"Convert an RGB tuple to a hex string.\"\"\"\n",
    "    return '#{:02x}{:02x}{:02x}'.format(int(rgb[0] * 255), int(rgb[1] * 255), int(rgb[2] * 255))\n",
    "\n",
    "\n",
    "colors = generate_hsi_colors(num_colors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some colors to the value map:\n",
    "for ind, map_element in enumerate(value_map.values()):\n",
    "    map_element.display_color = colors[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a torch Dataset returning (image, merged_mask) pairs:\n",
    "class LIACIDataset(Dataset):\n",
    "    def __init__(self, root, inverse_value_map):\n",
    "        self.root = root\n",
    "        self.inverse_value_map = inverse_value_map\n",
    "        image_folder = f\"{root}/images\"\n",
    "        self.image_files = os.listdir(image_folder)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.image_files[idx]\n",
    "        image_path = f\"{self.root}/images/{image_file}\"\n",
    "        image = Image.open(image_path)\n",
    "        mask = self._make_mask(image_file.replace(\".jpg\", \".bmp\"))\n",
    "        return image, mask\n",
    "\n",
    "    def _make_mask(self, image_file) -> Image:\n",
    "        # Merge all 10 binary masks into a single multiclass mask for this image\n",
    "        # Create an empty array for the categorical mask, initialized to 0 (background)\n",
    "        mask_shape = None\n",
    "        merged_mask = None\n",
    "\n",
    "        # Iterate over all categories\n",
    "        for category, category_id in self.inverse_value_map.items():\n",
    "            # Build the path to the current category mask\n",
    "            category_mask_path = f\"{self.root}/masks/{category}/{image_file}\"\n",
    "\n",
    "            # Open the binary mask for this category\n",
    "            category_mask = Image.open(category_mask_path)\n",
    "\n",
    "            # Convert the category mask to a numpy array\n",
    "            category_mask_array = np.array(category_mask)\n",
    "\n",
    "            # Ensure that the merged mask is initialized only once, with the correct shape\n",
    "            if mask_shape is None:\n",
    "                mask_shape = category_mask_array.shape\n",
    "                merged_mask = np.zeros(mask_shape, dtype=np.uint8)\n",
    "\n",
    "            # Assign the category ID to the merged mask wherever the binary mask is 1\n",
    "            merged_mask[category_mask_array == 1] = category_id\n",
    "\n",
    "        # Convert the merged mask back to a PIL Image\n",
    "        categorical_mask = Image.fromarray(merged_mask)\n",
    "\n",
    "        return categorical_mask\n",
    "\n",
    "\n",
    "dataset = LIACIDataset(DATASET_ROOT, simple_value_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_mask_table = tlc.Table.from_torch_dataset(\n",
    "    dataset,\n",
    "    (tlc.PILImage(\"image\"), tlc.SegmentationPILImage(\"segmentation_map\", classes=value_map)),\n",
    "    project_name=PROJECT_NAME,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    table_name=\"merged-masks\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3: Import Separate Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIACIDatasetV2(Dataset):\n",
    "    def __init__(self, root, inverse_value_map):\n",
    "        self.root = root\n",
    "        self.inverse_value_map = inverse_value_map\n",
    "        image_folder = f\"{root}/images\"\n",
    "        self.image_files = os.listdir(image_folder)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.image_files[idx]\n",
    "        image_path = f\"{self.root}/images/{image_file}\"\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        masks = (\n",
    "            Image.open(f\"{self.root}/masks/{label}/{image_file.replace('.jpg', '.bmp')}\")\n",
    "            for label in self.inverse_value_map.keys()\n",
    "        )\n",
    "        return image, *masks\n",
    "\n",
    "dataset = LIACIDatasetV2(DATASET_ROOT, simple_value_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_structures = (\n",
    "    tlc.SegmentationPILImage(\n",
    "        f\"{label.internal_name}_mask\",\n",
    "        classes={0.0: tlc.MapElement(\"background\"), 255.0: label},\n",
    "    )\n",
    "    for label in enumerate(\n",
    "        value_map.values(),\n",
    "    )\n",
    ")\n",
    "structure = (tlc.PILImage(\"image\"), *mask_structures)\n",
    "\n",
    "separate_masks_table = tlc.Table.from_torch_dataset(\n",
    "    dataset,\n",
    "    structure,\n",
    "    project_name=PROJECT_NAME,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    table_name=\"separate-masks\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
