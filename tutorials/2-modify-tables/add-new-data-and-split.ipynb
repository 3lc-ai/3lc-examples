{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new data to dataset with splits\n",
    "\n",
    "When adding new incoming data to a dataset that already has several split tables, there are two ways to go about it:\n",
    "1. Merge all the data into one table, and then create new splits from this table.\n",
    "2. Create new split Tables for the incoming data and then join those with the corresponding existing tables.\n",
    "\n",
    "Here we will show each of these in turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tlc\n",
    "\n",
    "from tools.split import split_table\n",
    "\n",
    "PROJECT_NAME = \"tutorials\"\n",
    "DATASET_NAME = \"add_new_data_merge_first\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Merge-first strategy\n",
    "\n",
    "![Merge First Strategy](../images/merge_first.png)\n",
    "\n",
    "The merge-first strategy first merges in the new data, and then creates new splits for all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train = tlc.Table.from_dict(data={\"my_column\": [1, 2, 3, 4, 5]}, project_name=PROJECT_NAME, dataset_name=DATASET_NAME, table_name=\"original_train\")\n",
    "original_val = tlc.Table.from_dict(data={\"my_column\": [6, 7, 8, 9, 10]}, project_name=PROJECT_NAME, dataset_name=DATASET_NAME, table_name=\"original_val\")\n",
    "original_test = tlc.Table.from_dict(data={\"my_column\": [11, 12, 13, 14, 15]}, project_name=PROJECT_NAME, dataset_name=DATASET_NAME, table_name=\"original_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_joined = tlc.Table.join_tables(\n",
    "    tables=[original_train, original_val, original_test],\n",
    "    project_name=PROJECT_NAME,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    table_name=\"original_joined\"\n",
    ")\n",
    "\n",
    "new = tlc.Table.from_dict(data={\"my_column\": [16, 17, 18, 19, 20]}, project_name=PROJECT_NAME, dataset_name=DATASET_NAME, table_name=\"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_joined = tlc.Table.join_tables(\n",
    "    tables=[original_joined, new],\n",
    "    project_name=PROJECT_NAME,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    table_name=\"all_joined\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a random split is used, but any strategy could be used. See 'split-tables.ipynb' for a more complete example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m3lc: \u001b[0mCreating transaction\n",
      "\u001b[90m3lc: \u001b[0mCommitting transaction\n",
      "\u001b[90m3lc: \u001b[0mCreating transaction\n",
      "\u001b[90m3lc: \u001b[0mCommitting transaction\n",
      "\u001b[90m3lc: \u001b[0mCreating transaction\n",
      "\u001b[90m3lc: \u001b[0mCommitting transaction\n"
     ]
    }
   ],
   "source": [
    "new_tables = split_table(\n",
    "    all_joined,\n",
    "    splits={\"train\": 0.34, \"val\": 0.33, \"test\": 0.33},\n",
    ")\n",
    "\n",
    "new_train = new_tables[\"train\"]\n",
    "new_val = new_tables[\"val\"]\n",
    "new_test = new_tables[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New train table: [2, 7, 9, 11, 14, 18, 19, 20]\n",
      "New val table: [3, 5, 6, 8, 10, 15]\n",
      "New test table: [1, 4, 12, 13, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "for split, table in new_tables.items():\n",
    "    print(f\"New {split} table: [\" + \", \".join(str(row[\"my_column\"]) for row in table) + \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split-first strategy\n",
    "\n",
    "![Split First Strategy](../images/split_first.png)\n",
    "\n",
    "The split-first strategy first splits the new data, and then merges each resulting split with the corresponding original splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"add_new_data_split_first\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train = tlc.Table.from_dict(data={\"my_column\": [1, 2, 3, 4, 5]}, project_name=PROJECT_NAME, dataset_name=DATASET_NAME, table_name=\"original_train\")\n",
    "original_val = tlc.Table.from_dict(data={\"my_column\": [6, 7, 8, 9, 10]}, project_name=PROJECT_NAME, dataset_name=DATASET_NAME, table_name=\"original_val\")\n",
    "original_test = tlc.Table.from_dict(data={\"my_column\": [11, 12, 13, 14, 15]}, project_name=PROJECT_NAME, dataset_name=DATASET_NAME, table_name=\"original_test\")\n",
    "\n",
    "new = tlc.Table.from_dict(data={\"my_column\": [16, 17, 18, 19, 20]}, project_name=PROJECT_NAME, dataset_name=DATASET_NAME, table_name=\"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m3lc: \u001b[0mCreating transaction\n",
      "\u001b[90m3lc: \u001b[0mCommitting transaction\n",
      "\u001b[90m3lc: \u001b[0mCreating transaction\n",
      "\u001b[90m3lc: \u001b[0mCommitting transaction\n",
      "\u001b[90m3lc: \u001b[0mCreating transaction\n",
      "\u001b[90m3lc: \u001b[0mCommitting transaction\n"
     ]
    }
   ],
   "source": [
    "new_tables_tmp = split_table(new, splits={\"train\": 0.34, \"val\": 0.33, \"test\": 0.33})\n",
    "\n",
    "new_train_tmp = new_tables_tmp[\"train\"]\n",
    "new_val_tmp = new_tables_tmp[\"val\"]\n",
    "new_test_tmp = new_tables_tmp[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = tlc.Table.join_tables(tables=[original_train, new_train_tmp], project_name=PROJECT_NAME, dataset_name=DATASET_NAME, table_name=\"new_train\")\n",
    "new_val = tlc.Table.join_tables(tables=[original_val, new_val_tmp], project_name=PROJECT_NAME, dataset_name=DATASET_NAME, table_name=\"new_val\")\n",
    "new_test = tlc.Table.join_tables(tables=[original_test, new_test_tmp], project_name=PROJECT_NAME, dataset_name=DATASET_NAME, table_name=\"new_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New train table: [2, 7, 9, 11, 14, 18, 19, 20]\n",
      "New val table: [3, 5, 6, 8, 10, 15]\n",
      "New test table: [1, 4, 12, 13, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "for split, table in new_tables.items():\n",
    "    print(f\"New {split} table: [\" + \", \".join(str(row[\"my_column\"]) for row in table) + \"]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
