{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QHnVupBBn9eR"
   },
   "source": [
    "# Training a finetuned SegFormer model with Pytorch Lightning\n",
    "\n",
    "This notebook is a modified version of the official Colab tutorial of \"Roboflow How to Train SegFormer\" which can be found [here](https://colab.research.google.com/drive/1250K828ixr-sG2xzLVYYN5AVa3cTaDEF).\n",
    "\n",
    "In this tutorial we will see how to fine-tune a pre-trained SegFormer model for semantic segmentation on a custom dataset.\n",
    "We will integrate with 3LC by creating a training run, registering 3LC datasets, and collecting per-sample predicted masks.\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "+ Training a SegFormer model on a custom dataset with Pytorch Lightning.\n",
    "+ Registering train/val/test sets into 3LC Tables\n",
    "+ Collecting per-sample semantic segmentation, predicted masks through callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "PROJECT_NAME = \"PyTorch Lightning Image Segmentation\"\n",
    "RUN_NAME = \"Train Balloon SegFormer\"\n",
    "DESCRIPTION = \"Train a SegFormer model using PyTorch Lightning\"\n",
    "TRAIN_DATASET_NAME = \"balloons-train\"\n",
    "VAL_DATASET_NAME = \"balloons-val\"\n",
    "TEST_DATASET_NAME = \"balloons-test\"\n",
    "TRANSIENT_DATA_PATH = \"../transient_data\"\n",
    "MODEL = \"nvidia/mit-b5\"\n",
    "TEST_DATA_PATH = \"../../tests/test_data/data\"\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 0\n",
    "TLC_PUBLIC_EXAMPLES_DEVELOPER_MODE = True\n",
    "INSTALL_DEPENDENCIES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Callable\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import tlc\n",
    "import torch\n",
    "from evaluate import load\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a 3LC Run\n",
    "\n",
    "First, we initialize a 3LC run. This will create a new empty run which will be visible in the 3LC dashboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = tlc.init(\n",
    "    project_name=PROJECT_NAME,\n",
    "    run_name=RUN_NAME,\n",
    "    description=DESCRIPTION,\n",
    "    if_exists=\"overwrite\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Datasets and Training helpers\n",
    "\n",
    "We will create a Table with the images and their associated masks.\n",
    "\n",
    "Moreover, we will also define helpers to preprocess this dataset into a suitable form for training and collecting metrics.\n",
    "\n",
    "To finish, we define a Pytorch LightningModule to define the steps for training, validation and test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d288Z2mF5dC",
    "outputId": "c47c5426-64d6-4632-f868-e2f14dfe39be"
   },
   "outputs": [],
   "source": [
    "class TLCSemanticSegmentationDataset(Dataset):\n",
    "    \"\"\"Image (semantic) segmentation dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, image_processor):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_processor = image_processor\n",
    "        image_file_names = [f for f in os.listdir(self.root_dir) if \".jpg\" in f]\n",
    "        mask_file_names = [f for f in os.listdir(self.root_dir) if \".png\" in f]\n",
    "        self.images = sorted(image_file_names)\n",
    "        self.masks = sorted(mask_file_names)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(os.path.join(self.root_dir, self.images[idx]))\n",
    "        segmentation_map = Image.open(os.path.join(self.root_dir, self.masks[idx]))\n",
    "        return image, segmentation_map, image.size, segmentation_map.size\n",
    "\n",
    "    def transform_to_seg_former_format(self, sample):\n",
    "        image, segmentation_map, _, _ = sample\n",
    "        encoded_inputs = self.image_processor(image, segmentation_map, return_tensors=\"pt\")\n",
    "        for k, _ in encoded_inputs.items():\n",
    "            encoded_inputs[k].squeeze_()  # remove batch dimension\n",
    "        return encoded_inputs\n",
    "\n",
    "    def transform_to_collect_metrics(self, sample):\n",
    "        sample_preprocessed = self.transform_to_seg_former_format(sample)\n",
    "        images, masks = sample_preprocessed[\"pixel_values\"], sample_preprocessed[\"labels\"]\n",
    "        return (images, masks) + sample[-2:]\n",
    "\n",
    "\n",
    "def get_id2label(root_dir):\n",
    "    classes_csv_file = os.path.join(root_dir, \"_classes.csv\")\n",
    "    with open(classes_csv_file) as fid:\n",
    "        data = [line.split(\",\") for idx, line in enumerate(fid) if idx != 0]\n",
    "    return {x[0]: x[1].strip() for x in data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegformerFinetuner(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        id2label,\n",
    "        image_processor,\n",
    "        train_dataloader=None,\n",
    "        val_dataloader=None,\n",
    "        test_dataloader=None,\n",
    "        metrics_interval=100,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.id2label = id2label\n",
    "        self.image_processor = image_processor\n",
    "        self.train_dl = train_dataloader\n",
    "        self.val_dl = val_dataloader\n",
    "        self.test_dl = test_dataloader\n",
    "        self.metrics_interval = metrics_interval\n",
    "\n",
    "        self.num_classes = len(id2label.keys())\n",
    "        self.label2id = {v: k for k, v in self.id2label.items()}\n",
    "\n",
    "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            MODEL,\n",
    "            return_dict=False,\n",
    "            num_labels=self.num_classes,\n",
    "            id2label=self.id2label,\n",
    "            label2id=self.label2id,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "        self.train_mean_iou = load(\"mean_iou\")\n",
    "        self.val_mean_iou = load(\"mean_iou\")\n",
    "        self.test_mean_iou = load(\"mean_iou\")\n",
    "\n",
    "        self.training_step_outputs = []  # >=2.0.0 fix\n",
    "        self.validation_step_outputs = []  # >=2.0.0 fix\n",
    "        self.test_step_outputs = []  # >=2.0.0 fix\n",
    "\n",
    "    def forward(self, images, masks):\n",
    "        outputs = self.model(pixel_values=images, labels=masks)\n",
    "        return outputs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, masks = batch[\"pixel_values\"], batch[\"labels\"]\n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, size=masks.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        self.train_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(),\n",
    "            references=masks.detach().cpu().numpy(),\n",
    "        )\n",
    "        if batch_idx % self.metrics_interval == 0:\n",
    "            metrics = self.train_mean_iou.compute(\n",
    "                num_labels=self.num_classes,\n",
    "                ignore_index=255,\n",
    "                reduce_labels=False,\n",
    "            )\n",
    "            metrics = {\n",
    "                \"loss\": loss,\n",
    "                \"mean_iou\": metrics[\"mean_iou\"],\n",
    "                \"mean_accuracy\": metrics[\"mean_accuracy\"],\n",
    "            }\n",
    "            for k, v in metrics.items():\n",
    "                self.log(k, v, prog_bar=True)\n",
    "\n",
    "        else:\n",
    "            metrics = {\"loss\": loss}\n",
    "\n",
    "        self.training_step_outputs.append(metrics)  # >=2.0.0 fix\n",
    "        return metrics\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        images, masks = batch[\"pixel_values\"], batch[\"labels\"]\n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, size=masks.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        self.val_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(),\n",
    "            references=masks.detach().cpu().numpy(),\n",
    "        )\n",
    "        self.validation_step_outputs.append(loss)  # >=2.0.0 fix\n",
    "\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.val_mean_iou.compute(\n",
    "            num_labels=self.num_classes,\n",
    "            ignore_index=255,\n",
    "            reduce_labels=False,\n",
    "        )\n",
    "\n",
    "        avg_val_loss = torch.stack(self.validation_step_outputs).mean()  # >=2.0.0 fix\n",
    "        val_mean_iou = metrics[\"mean_iou\"]\n",
    "        val_mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "\n",
    "        metrics = {\n",
    "            \"val_loss\": avg_val_loss,\n",
    "            \"val_mean_iou\": val_mean_iou,\n",
    "            \"val_mean_accuracy\": val_mean_accuracy,\n",
    "        }\n",
    "        for k, v in metrics.items():\n",
    "            self.log(k, v, prog_bar=True)\n",
    "\n",
    "        self.validation_step_outputs.clear()  # >=2.0.0 fix\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        images, masks = batch[\"pixel_values\"], batch[\"labels\"]\n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, size=masks.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        self.test_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(),\n",
    "            references=masks.detach().cpu().numpy(),\n",
    "        )\n",
    "        self.test_step_outputs.append(loss)  # >=2.0.0 fix\n",
    "\n",
    "        return {\"test_loss\": loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        metrics = self.test_mean_iou.compute(\n",
    "            num_labels=self.num_classes,\n",
    "            ignore_index=255,\n",
    "            reduce_labels=False,\n",
    "        )\n",
    "\n",
    "        avg_test_loss = torch.stack(self.test_step_outputs).mean()  # >=2.0.0 fix\n",
    "        test_mean_iou = metrics[\"mean_iou\"]\n",
    "        test_mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "        metrics = {\n",
    "            \"test_loss\": avg_test_loss,\n",
    "            \"test_mean_iou\": test_mean_iou,\n",
    "            \"test_mean_accuracy\": test_mean_accuracy,\n",
    "        }\n",
    "        for k, v in metrics.items():\n",
    "            self.log(k, v)\n",
    "        self.test_step_outputs.clear()  # >=2.0.0 fix\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=2e-05, eps=1e-08)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_dl\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_dl\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = SegformerImageProcessor.from_pretrained(\n",
    "    MODEL,\n",
    "    reduce_labels=False,\n",
    "    size=128,\n",
    ")\n",
    "dataset_location = tlc.Url(TEST_DATA_PATH + \"/balloons-mask-segmentation\").to_absolute()\n",
    "\n",
    "id2label = get_id2label(f\"{dataset_location}/train/\")  # Assuming the same classes for train, val, and test\n",
    "structure = (\n",
    "    tlc.PILImage(\"image\"),\n",
    "    tlc.SegmentationPILImage(\"mask\", id2label),\n",
    "    tlc.HorizontalTuple(\"image size\", [tlc.Int(\"width\"), tlc.Int(\"height\")]),\n",
    "    tlc.HorizontalTuple(\"mask size\", [tlc.Int(\"width\"), tlc.Int(\"height\")]),\n",
    ")\n",
    "\n",
    "tlc_train_dataset = TLCSemanticSegmentationDataset(f\"{dataset_location}/train/\", image_processor)\n",
    "tlc_train_dataset = (\n",
    "    tlc.Table.from_torch_dataset(\n",
    "        dataset=tlc_train_dataset,\n",
    "        structure=structure,\n",
    "        table_name=\"train_dataset\",\n",
    "        dataset_name=TRAIN_DATASET_NAME,\n",
    "        project_name=PROJECT_NAME,\n",
    "        if_exists=\"overwrite\",\n",
    "    )\n",
    "    .map(tlc_train_dataset.transform_to_seg_former_format)\n",
    "    .map_collect_metrics(tlc_train_dataset.transform_to_collect_metrics)\n",
    ")\n",
    "\n",
    "tlc_val_dataset = TLCSemanticSegmentationDataset(f\"{dataset_location}/valid/\", image_processor)\n",
    "tlc_val_dataset = (\n",
    "    tlc.Table.from_torch_dataset(\n",
    "        dataset=tlc_val_dataset,\n",
    "        structure=structure,\n",
    "        table_name=\"val_dataset\",\n",
    "        dataset_name=VAL_DATASET_NAME,\n",
    "        project_name=PROJECT_NAME,\n",
    "        if_exists=\"overwrite\",\n",
    "    )\n",
    "    .map(tlc_val_dataset.transform_to_seg_former_format)\n",
    "    .map_collect_metrics(tlc_val_dataset.transform_to_collect_metrics)\n",
    ")\n",
    "\n",
    "tlc_test_dataset = TLCSemanticSegmentationDataset(f\"{dataset_location}/test/\", image_processor)\n",
    "tlc_test_dataset = (\n",
    "    tlc.Table.from_torch_dataset(\n",
    "        dataset=tlc_test_dataset,\n",
    "        structure=structure,\n",
    "        table_name=\"test_dataset\",\n",
    "        dataset_name=TEST_DATASET_NAME,\n",
    "        project_name=PROJECT_NAME,\n",
    "    )\n",
    "    .map(tlc_test_dataset.transform_to_seg_former_format)\n",
    "    .map_collect_metrics(tlc_test_dataset.transform_to_collect_metrics)\n",
    ")\n",
    "\n",
    "\n",
    "sampler = tlc_train_dataset.create_sampler()\n",
    "\n",
    "train_dataloader = DataLoader(tlc_train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, sampler=sampler)\n",
    "val_dataloader = DataLoader(tlc_val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "test_dataloader = DataLoader(tlc_test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "segformer_finetuner = SegformerFinetuner(\n",
    "    id2label,\n",
    "    image_processor=image_processor,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    metrics_interval=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Callback to register predicted mask to 3LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tlc.client.torch.metrics.metrics_collectors.segmentation_metrics_collector import SegmentationMetricsCollector\n",
    "\n",
    "metrics_collection_dataloader_args = {\n",
    "    \"num_workers\": NUM_WORKERS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "}\n",
    "\n",
    "\n",
    "class MetricsCollectionCallBack(pl.Callback):\n",
    "    def __init__(self, dataset, post_process_function: Callable[[Any], object]) -> None:\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.post_process_function = post_process_function\n",
    "\n",
    "    def on_train_epoch_end(\n",
    "        self, trainer, pl_module\n",
    "    ):  # You could define this inside  on_train_end if you just want to run on the last epoch.\n",
    "        segmentation_metrics_collector = SegmentationMetricsCollector(\n",
    "            segmentation_model=pl_module.model,\n",
    "            id2label=id2label,\n",
    "            post_process_function=self.post_process_function,\n",
    "            current_epoch=pl_module.current_epoch,\n",
    "        )\n",
    "        pl_module.eval()\n",
    "        tlc.collect_metrics(\n",
    "            table=self.dataset,\n",
    "            metrics_collectors=[segmentation_metrics_collector],\n",
    "            constants={\"epoch\": pl_module.current_epoch},\n",
    "            dataloader_args=metrics_collection_dataloader_args,\n",
    "        )\n",
    "        pl_module.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=1, monitor=\"val_loss\", save_last=True)\n",
    "\n",
    "collect_metrics_on_train = MetricsCollectionCallBack(\n",
    "    dataset=tlc_train_dataset, post_process_function=image_processor.post_process_semantic_segmentation\n",
    ")  # Setting up the callback on the train dataset to collect metrics\n",
    "\n",
    "collect_metrics_on_test = MetricsCollectionCallBack(\n",
    "    dataset=tlc_test_dataset, post_process_function=image_processor.post_process_semantic_segmentation\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    callbacks=[early_stop_callback, checkpoint_callback, collect_metrics_on_train, collect_metrics_on_test],\n",
    "    max_epochs=EPOCHS,\n",
    "    val_check_interval=len(train_dataloader),\n",
    "    log_every_n_steps=7,\n",
    ")\n",
    "\n",
    "trainer.fit(segformer_finetuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = trainer.test(ckpt_path=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch = next(iter(test_dataloader))\n",
    "images, masks = batch[\"pixel_values\"].to(DEVICE), batch[\"labels\"].to(DEVICE)\n",
    "segformer_finetuner.eval().to(DEVICE)\n",
    "outputs = segformer_finetuner.model(images, masks, return_dict=True)\n",
    "batch_prediction = image_processor.post_process_semantic_segmentation(outputs, [(640, 640)] * 8)\n",
    "loss, logits = outputs[0], outputs[1]\n",
    "\n",
    "n_plots = len(images)\n",
    "fig, ax = plt.subplots(n_plots, 3)\n",
    "fig.set_figheight(30)\n",
    "fig.set_figwidth(30)\n",
    "fig.subplots_adjust(wspace=-0.80)\n",
    "for i in range(n_plots):\n",
    "    ax[i, 0].imshow(masks[i, :, :].cpu().numpy(), cmap=\"gray\")\n",
    "    ax[i, 0].set_title(\"Mask id=\" + str(i))\n",
    "\n",
    "    ax[i, 1].imshow(batch_prediction[i].cpu().numpy(), cmap=\"gray\")\n",
    "    ax[i, 1].set_title(\"Predicted mask from model id=\" + str(i))\n",
    "\n",
    "    im = Image.open(run.metrics_tables[-1].table_rows[i][\"predicted_mask\"])\n",
    "    ax[i, 2].imshow(np.array(im), cmap=\"gray\")\n",
    "    ax[i, 2].set_title(\"Predicted mask from 3lc id=\" + str(i))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
