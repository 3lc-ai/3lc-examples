{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face CIFAR-100 Embeddings Example\n",
    "\n",
    "In this notebook we will see how to use a pre-trained Vision Transformers (ViT) model to collect embeddings on the CIFAR-100 dataset.\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "- Registering the `CIFAR-100` dataset from Hugging Face.\n",
    "- Computing image embeddings with `transformers` and reducing them to 2D with UMAP.\n",
    "- Adding the computed embeddings as metrics to a 3LC `Run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"CIFAR-100 Embeddings\"\n",
    "DEVICE = 'cuda:0'\n",
    "TRAIN_DATASET_NAME=\"hf-cifar-100-train\"\n",
    "TEST_DATASET_NAME=\"hf-cifar-100-test\"\n",
    "MODEL = 'google/vit-base-patch16-224'\n",
    "BATCH_SIZE = 32\n",
    "INSTALL_DEPENDENCIES=False\n",
    "TLC_PUBLIC_EXAMPLES_DEVELOPER_MODE = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INSTALL_DEPENDENCIES:\n",
    "    %pip --quiet install ipykernel ipywidgets\n",
    "    %pip --quiet install datasets transformers\n",
    "    %pip --quiet install torch --index-url https://download.pytorch.org/whl/cu118\n",
    "    %pip --quiet install torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "    %pip --quiet install tlc[umap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HIDDEN CELL ###\n",
    "\n",
    "## Data & Alias management\n",
    "# See comments in ../mnist.ipynb for details on data and alias management.\n",
    "\n",
    "# Set this variable to True if you just want to run this notebook for local testing purposes\n",
    "if not TLC_PUBLIC_EXAMPLES_DEVELOPER_MODE:\n",
    "    from tlc.client.utils import (\n",
    "        TLC_PUBLIC_EXAMPLES_RUN_ROOT,\n",
    "        TLC_PUBLIC_EXAMPLES_TABLE_ROOT,\n",
    "        TLC_PUBLIC_EXAMPLES_CIFAR_100_DATA_ALIAS_NAME,\n",
    "        TLC_PUBLIC_EXAMPLES_CIFAR_100_DATA_ALIAS_VALUE,\n",
    "    )\n",
    "    from tlc.core.objects.mutable_objects import Configuration\n",
    "    from tlc.core.url import UrlAliasRegistry, Url\n",
    "\n",
    "    print(f\"Runs and Tables will be written to remote location: '{TLC_PUBLIC_EXAMPLES_RUN_ROOT}' and '{TLC_PUBLIC_EXAMPLES_TABLE_ROOT}'\")\n",
    "    Configuration.instance().run_root_url = TLC_PUBLIC_EXAMPLES_RUN_ROOT\n",
    "    Configuration.instance().table_root_url = TLC_PUBLIC_EXAMPLES_TABLE_ROOT\n",
    "\n",
    "    print(f\"CIFAR-100 data will be written to local SAMPLE_ROOT: '{Configuration.instance().sample_root_url}'\\n\")\n",
    "\n",
    "    LOCAL_CIFAR100_DATA_LOCATION = (Url(Configuration.instance().sample_root_url) / PROJECT_NAME).to_str()\n",
    "\n",
    "    print(f\"In this notebook, the alias '{TLC_PUBLIC_EXAMPLES_CIFAR_100_DATA_ALIAS_NAME}' refers to the cifar-10 data at '{LOCAL_CIFAR100_DATA_LOCATION}'\\n\")\n",
    "\n",
    "    print(\"After this run has completed, the data will be uploaded using the following command:\")\n",
    "    print(f\"\\taws s3 sync {Configuration.instance().sample_root_url}/{PROJECT_NAME} {TLC_PUBLIC_EXAMPLES_CIFAR_100_DATA_ALIAS_VALUE}\")\n",
    "\n",
    "    UrlAliasRegistry.instance().register_url_alias(\n",
    "        TLC_PUBLIC_EXAMPLES_CIFAR_100_DATA_ALIAS_NAME,\n",
    "        LOCAL_CIFAR100_DATA_LOCATION,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "To read the data into 3LC, we use `load_dataset` available under the Hugging Face integration. This returns a `TLCDataset`, which presents samples under `.get_sample_at_index(index)` with the same sample structure as a Hugging Face `datasets.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tlc.integration.huggingface import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_train = load_dataset(\n",
    "    \"cifar100\",\n",
    "    split=\"train\",\n",
    "    project_name=PROJECT_NAME,\n",
    "    dataset_name=TRAIN_DATASET_NAME,\n",
    "    write_row_cache=True,\n",
    ")\n",
    "\n",
    "cifar100_test = load_dataset(\n",
    "    \"cifar100\",\n",
    "    split=\"test\",\n",
    "    project_name=PROJECT_NAME,\n",
    "    dataset_name=TEST_DATASET_NAME,\n",
    "    write_row_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_train.sample_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_train[0][\"img\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_element = cifar100_train.sample_structure.sample_structure['fine_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_element.int_to_str(cifar100_train[0][\"fine_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the data\n",
    "\n",
    "We then use the `transformers` library to compute embeddings and `umap-learn` to reduce the embeddings to two dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(DEVICE)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(MODEL)\n",
    "model = ViTModel.from_pretrained(MODEL).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_feature = lambda sample: feature_extractor(images=sample['img'], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def infer_on_dataset(dataset):\n",
    "    activations = []\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    for inputs in tqdm(dataloader, total=dataloader.__len__()):\n",
    "        inputs['pixel_values'] = inputs['pixel_values'].squeeze()\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        outputs = model(**inputs)\n",
    "        activations.append(outputs.last_hidden_state[:, 0, :].detach().cpu())\n",
    "\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = []\n",
    "model.eval()\n",
    "\n",
    "for dataset in (cifar100_train, cifar100_test):\n",
    "    dataset = dataset.map(extract_feature)\n",
    "    activations.extend(infer_on_dataset(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = torch.cat(activations).numpy()\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "reducer = umap.UMAP(n_components=2)\n",
    "embeddings_2d = reducer.fit_transform(activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the embeddings as 3LC metrics\n",
    "\n",
    "In this example the metrics are contained in a `numpy.ndarray` object. We can specify the schema of this data and provide it directly to 3LC using `Run.add_metrics_data()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tlc\n",
    "\n",
    "run = tlc.init(project_name=PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_schema = tlc.Schema(\n",
    "    value=tlc.Float32Value(),\n",
    "    size0=tlc.DimensionNumericValue(value_min=2, value_max=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_2d_train = embeddings_2d[:len(cifar100_train)]\n",
    "embeddings_2d_test = embeddings_2d[len(cifar100_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_2d_train = embeddings_2d[:len(cifar100_train)]\n",
    "embeddings_2d_test = embeddings_2d[len(cifar100_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "### HIDDEN CELL ###\n",
    "import numpy as np\n",
    "try:\n",
    "    TwoBatchPatchDataLoader\n",
    "    # The two batch patch is active, so we need to split and pad embeddings_2d to match input table lengths.\n",
    "    # \n",
    "    # # Calculate the number of embeddings for each dataset based on the batch processing\n",
    "    num_embeddings_train = 2 * BATCH_SIZE  # 2 batches of size for training\n",
    "    num_embeddings_test = len(embeddings_2d) - num_embeddings_train  # remaining for testing\n",
    "\n",
    "    # Split the embeddings\n",
    "    embeddings_2d_train = embeddings_2d[:num_embeddings_train]\n",
    "    embeddings_2d_test = embeddings_2d[num_embeddings_train:num_embeddings_train + num_embeddings_test]\n",
    "\n",
    "    # Pad the embeddings with ones to match the size of the original datasets\n",
    "    pad_length_train = len(cifar100_train) - len(embeddings_2d_train)\n",
    "    pad_length_test = len(cifar100_test) - len(embeddings_2d_test)\n",
    "\n",
    "    if pad_length_train > 0:\n",
    "        embeddings_2d_train = np.vstack((embeddings_2d_train, np.ones((pad_length_train, embeddings_2d_train.shape[1]))))\n",
    "\n",
    "    if pad_length_test > 0:\n",
    "        embeddings_2d_test = np.vstack((embeddings_2d_test, np.ones((pad_length_test, embeddings_2d_test.shape[1])))) \n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, embeddings in ((cifar100_train, embeddings_2d_train), (cifar100_test, embeddings_2d_test)):\n",
    "    run.add_metrics_data(\n",
    "        {\"embeddings\": [row for row in embeddings]},\n",
    "        override_column_schemas={\"embeddings\": embedding_schema},\n",
    "        input_table_url=dataset.url\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "### HIDDEN CELL ###\n",
    "\n",
    "if not TLC_PUBLIC_EXAMPLES_DEVELOPER_MODE:\n",
    "    print(\"Uploading data to S3...\")\n",
    "    !aws s3 sync \"{(tlc.Url(Configuration.instance().sample_root_url)/PROJECT_NAME).to_str()}\" {TLC_PUBLIC_EXAMPLES_CIFAR_100_DATA_ALIAS_VALUE}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
